## 변환기 만들기

https://github.com/mhso-dev/bit-python/blob/master/02_%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D%EC%9D%84_%EC%9C%84%ED%95%9C_%EB%8D%B0%EC%9D%B4%ED%84%B0_%EB%B6%84%EC%84%9D%EA%B3%BC_%EC%B2%98%EB%A6%AC.ipynb



### 사이킷 런의 알고리즘 모델

- 추정기(BaseEstimator)

알고리즘을 적용시킨 모델을 만들 수 있음

fit: 데이터 적용(훈련)

> 알고리즘을 데이터에 적용시킨다고 생각하면 됨

predict: 



- 변환기(Transformer)

transform:

> 트랜스폼 전에 fit이 완료되어 있어야 함

fit_transform: fit()과 transform() 호출 해줌



- 파이프라인?

```
Pipeline
[작업, 작업, 작업, 작업...]
작업: housing dataset의 특성 조합
```

> 작업을 하나의 단위로 처리하기 위한 것





### 나만의 추정기 만들기

```python
# TransformerMixin: 자동으로 상속되는 클래스에 fit_transform() 메서드를 생성해 줌
from sklearn.base import BaseEstimator, TransformerMixin

rooms_ix, bedrooms_ix, population_ix, households_ix = 3, 4, 5, 6

class CombinedAttributesAdder(BaseEstimator, TransformerMixin):

  # 변환 정책에 대한 초기화
  # 기본 파라미터로 add_bedrooms_per_room을 사용하겠다(디폴트)
  def __init__(self, add_bedrooms_per_room = True):
    self.add_bedrooms_per_room = add_bedrooms_per_room
  
  # 데이터를 적용시키는 구간(데이터를 받는 역할)
  # 각종 알고리즘을 넣는 공간이지만 데이터를 단순히 집어 넣고 변환을 하기 위해 슈퍼클래스 호출(X 파라미터로 초기화)
  def fit(self, X):
    return self

  # 변환기
  def transform(self, X): 
    # rooms_per_household 변환
    rooms_per_household = X[:, rooms_ix]  / X[:, households_ix] # 가구당 방 비율 구하기
    # population_per_household 변환
    population_per_household = X[:, population_ix] / X[:, households_ix] # 가구당 인구수 구하기
    # 초기화 했었던 정책에 의한 변환
    if self.add_bedrooms_per_room:
      bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]
      return np.c_[X, rooms_per_household, population_per_household, bedrooms_per_room]

    else:
      return np.c_[X, rooms_per_household, population_per_household]

attr_adder = CombinedAttributesAdder(add_bedrooms_per_room= False)
housing_extra_attribs = attr_adder.transform(housing.values)
```

```python
attr_addr = CombinedAttributesAdder(False)
housing_extra_attribs = attr_adder.transform(housing.values)
housing_extra_attribs[:3]
```

```
array([[-121.89, 37.29, 38.0, 1568.0, 351.0, 710.0, 339.0, 2.7042,
        '<1H OCEAN', 2, 4.625368731563422, 2.094395280235988],
       [-121.93, 37.05, 14.0, 679.0, 108.0, 306.0, 113.0, 6.4214,
        '<1H OCEAN', 5, 6.008849557522124, 2.7079646017699117],
       [-117.2, 32.77, 31.0, 1952.0, 471.0, 936.0, 462.0, 2.8621,
        'NEAR OCEAN', 2, 4.225108225108225, 2.0259740259740258]],
      dtype=object)
```





### 특성 스케일링

> 특성을 정규화 시키는 것
>
> 각 특성들간의 값 차이를 줄이기 위해 스케일링을 사용함(스케일링이 되어있지 않으면 성능에서 차이가 남)



- 정규화?

알고리즘에 맞게 데이터의 폼을 변경시키는 것

> 구글 드라이브의 정규화.html 참조





### 변환 파이프라인 만들기

> 누락값 채우기 -> 변환시키기 -> 스케일링

```python

from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler

# 파이프라인은 알고리즘을 만들기 위한 과정들을 엮어 놓은 것
# 제일 마지막 과정은 변환기/추정기 상관 없음
# 마지막 이전 과정은 무조건 변환기여야만 함(fit_transform 또는 fit, transform 메서드가 있어야 함)
# 맨 마지막은 결과를 내는 과정(변환기/추청기 상관 없음), 그 이전 과정은 변환하는 과정(변환기)
# imputer: 누락값 채우기 부분
# attribs_attr: 특성 추가
# std_scaler: 스탠다드 스케일러
num_pipeline = Pipeline([
                         ('imputer', SimpleImputer(strategy="median")),
                         ("attribs_attr", CombinedAttributesAdder()),
                         ("std_scaler", StandardScaler())
])

housing_num_tr = num_pipeline.fit_transform(housing_num)
```

```python
# 특정 컬럼만 선택해서 변환하는 ColumnTransformer
from sklearn.compose import ColumnTransformer

num_attribs = list(housing_num) # 수치형 데이터 가지고 오기(변환 안된 것)
cat_attribs = ["ocean_proximity"]

# 수치 데이터는 num_pipeline으로 처리
# 카테고리 데이터는 OneHotEncoder로 따로 처리
full_pipeline = ColumnTransformer([
                                   ("num", num_pipeline, num_attribs),
                                   ("cat", OneHotEncoder(), cat_attribs),
])

housing_prepared = full_pipeline.fit_transform(housing)
housing_prepared[:3]
```

```
array([[-1.15604281,  0.77194962,  0.74333089, -0.49323393, -0.44543821,
        -0.63621141, -0.42069842, -0.61493744, -0.95445595, -0.31205452,
        -0.08649871,  0.15531753,  1.        ,  0.        ,  0.        ,
         0.        ,  0.        ],
       [-1.17602483,  0.6596948 , -1.1653172 , -0.90896655, -1.0369278 ,
        -0.99833135, -1.02222705,  1.33645936,  1.89030518,  0.21768338,
        -0.03353391, -0.83628902,  1.        ,  0.        ,  0.        ,
         0.        ,  0.        ],
       [ 1.18684903, -1.34218285,  0.18664186, -0.31365989, -0.15334458,
        -0.43363936, -0.0933178 , -0.5320456 , -0.95445595, -0.46531516,
        -0.09240499,  0.4222004 ,  0.        ,  0.        ,  0.        ,
         0.        ,  1.        ]])
```





## 머신러닝 알고리즘 모델 선택과 훈련

### 선형 회귀 모델

```python
from sklearn.linear_model import LinearRegression

lin_reg = LinearRegression()
lin_reg.fit(housing_prepared, housing_labels)
```

```
LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)
```

> n_jobs: 사용된 cpu 개수



```python
# 데이터 준비
example_train_data = housing.iloc[:5]
example_labels = housing_labels.iloc[:5]

example_data_prepared = full_pipeline.transform(example_train_data) # 파이프라인을 이용한 데이터 변환

lin_reg.predict(example_data_prepared) # 예측
print(example_labels)
print()

print("예측 : {}".format(lin_reg.predict(example_data_prepared))) # 변환한 데이터로 예측
print("레이블 : {}".format(list(example_labels)))
```

```
17606    286600.0
18632    340600.0
14650    196900.0
3230      46300.0
3555     254500.0
Name: median_house_value, dtype: float64

예측 : [203682.37379543 326371.39370781 204218.64588245  58685.4770482
 194213.06443039]
레이블 : [286600.0, 340600.0, 196900.0, 46300.0, 254500.0]
```



- 측정함수

```
					측정함수
		스코어링				손실
		높으면 좋다				낮으면 좋다
		(머신러닝)				(딥러닝)
```



- 회귀에서 사용되는 성능 지표 함수

1. MSE: 대부분 상황에서 사용

```
시그마i=1부터 m까지(yi - 햇yi)^2 / m

m = 전체 개수
y = 타겟
햇y = 모델이 예측한 값
```

> 미분이 가능
>
> 모든것들의 평균
>
> 오차에 제곱
>
> (정답 - 예측)^2 = 유클라디안 거리
>
> L2 놀음

2. MAE: 이상치가 많을 때 사용

```
시그마i=1부터 m까지|yi - 햇yi| / m

m = 전체 개수
y = 타겟
햇y = 모델이 예측한 값
```

> MSE가 MAE 보다 많이 사용함
>
> 오차에 절대값
>
> |정답 - 예측| = 맨하튼 거리
>
> L1 놀음

=> 두 방법 모두 성능측정(낮을수록 좋음)



### 모델의 성능 평가하기

```python
from sklearn.metrics import mean_squared_error
housing_predictions = lin_reg.predict(housing_prepared)

# MSE를 먼저 구하기(정답, 예측값)
lin_mse = mean_squared_error(housing_labels, housing_predictions)
print(lin_mse)

# Root를 씌우면 RMSE 완성
lin_mse = np.sqrt(lin_mse)
print(lin_mse)
```

```
4675365301.740765
68376.64295459937
```

> 모델이 과소적합 되어있음(훈련 데이터를 제대로 보지 못함)
>
> 모델을 수정하거나(하이퍼 파라미터 등) 데이터를 세분화 해야함 





### 트리 모델

```python
# 의사 결정 회귀 나무
from sklearn.tree import DecisionTreeRegressor

tree_reg = DecisionTreeRegressor()
tree_reg.fit(housing_prepared, housing_labels)
```

```
DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,
                      max_features=None, max_leaf_nodes=None,
                      min_impurity_decrease=0.0, min_impurity_split=None,
                      min_samples_leaf=1, min_samples_split=2,
                      min_weight_fraction_leaf=0.0, presort='deprecated',
                      random_state=None, splitter='best')
```

```python
housing_predictions = tree_reg.predict(housing_prepared)
tree_mse = mean_squared_error(housing_labels, housing_predictions)
tree_rmse = np.sqrt(tree_mse)

tree_rmse
```

```
0.0
```

> 오차가 0이니 과대적합 되었다는 뜻(DT는 무조건 과적합 하게 되어있음)

> 디시전 트리가 train셋에 대해선 성능이 굉장히 좋지만 test셋에 대해선 안 좋음





## 교차검증

- 그러면 테스트 셋은 언제 사용하나?

테스트 셋은 런칭 직전에 테스트 하는 용도로 사용해야 함

따라서 "검증셋"으로 훈련된 것을 검증해봐야함



- 교차검증?

```
100개의 데이터
그 중 20은 테스트 세트로 남김
나머지 80을 4개의 세트로 나누어서, 
3개는 트레이닝 셋 + 1개는 검증셋으로 설정 후 1개의 검증셋을 교차로 바꿔보며 평균 오차를 찾아내는 것

```

> 4개의 세트로 나눈것을 모델 훈련용 데이터라고 함



```python
# 스코어는 높을 수록 좋음(오차는 낮을 수록 좋음)
from sklearn.model_selection import cross_val_score

# 트리 모델 넣음
# scoring은 accuracy를 점수 측정하는 것이지만 해당 파라미터를 오차라는 것을 넣어주므로써 해결
# cv는 폴드의 개수
scores = cross_val_score(tree_reg, housing_prepared, housing_labels,
                         scoring="neg_mean_squared_error", cv=10)

# negative이므로 마이너스를 붙임
tree_rmse_scores = np.sqrt(-scores)
```

```python
def display_scores(scores):
  print("점수 : ", scores)
  print("평균 : ", scores.mean())
  print("표준편차 : ", scores.std())

# tree_rmse_scores 결과 보기
display_scores(tree_rmse_scores)
```

```
점수 :  [68446.3905607  67367.05391234 70817.00600727 68696.45831758
 70276.80781006 74335.08787213 69430.44953061 70804.44098043
 77309.06581052 69902.21818978]
평균 :  70738.49789914276
표준편차 :  2820.144719860578
```

> 표준편차가 크면 클 수록 신뢰구간을 만들어내지 못 한 것이므로 편차가 적어야 좋음



```python
# 선형회귀 모델 넣음
lin_scores = cross_val_score(lin_reg, housing_prepared, housing_labels,
                             scoring="neg_mean_squared_error", cv=10)

lin_rmse_scores = np.sqrt(-lin_scores)
display_scores(lin_rmse_scores)
```

```
점수 :  [66877.52325028 66608.120256   70575.91118868 74179.94799352
 67683.32205678 71103.16843468 64782.65896552 67711.29940352
 71080.40484136 67687.6384546 ]
평균 :  68828.99948449328
표준편차 :  2662.7615706103393
```

> 선형회귀가 트리보다 안정적으로 예측을 했다로 볼 수 있음





### 앙상블 모델

> 서로 다른 모델을 합쳐서 하나의 결과를 냄

```python
# 앙상블 모델
# 랜덤 포레스트 사용
from sklearn.ensemble import RandomForestRegressor
forest_reg = RandomForestRegressor()
forest_reg.fit(housing_prepared, housing_labels)
print(forest_reg)

# 교차 검증을 하지 않았을 때의 점수
# 원래는 교차검증을 하거나 폴드를 3, 5, 7, 10으로 설정하여 학습을 시켜야함
# 하지만 시간이 없을 땐 해당 방식으로 학습시킴
forest_predicted = forest_reg.predict(housing_prepared)
forest_mse = mean_squared_error(housing_labels, forest_predicted)
forest_rmse = np.sqrt(forest_mse)
print("교차 검증을 하지 않은 랜덤 포레스트의 점수 : ", forest_rmse)
```

```
RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',
                      max_depth=None, max_features='auto', max_leaf_nodes=None,
                      max_samples=None, min_impurity_decrease=0.0,
                      min_impurity_split=None, min_samples_leaf=1,
                      min_samples_split=2, min_weight_fraction_leaf=0.0,
                      n_estimators=100, n_jobs=None, oob_score=False,
                      random_state=None, verbose=0, warm_start=False)
교차 검증을 하지 않은 랜덤 포레스트의 점수 :  18624.544598547745
```



```python
# 교차 검증을 수행했을 때의 점수
# 랜덤포레스트 사용
forest_mse_scores = cross_val_score(RandomForestRegressor(), housing_prepared, housing_labels, 
                                     scoring="neg_mean_squared_error", cv=10)

forest_rmse_scores = np.sqrt(-forest_mse_scores)

display_scores(forest_rmse_scores)
```

```
점수 :  [49565.01341304 47871.07674719 49985.54687941 52521.88257187
 49872.39241962 53544.82366836 49145.63019993 48218.7592004
 53315.35471649 50182.27616984]
평균 :  50422.27559861422
표준편차 :  1918.543403428116
```



```python
# 모델을 파일로 저장하기
import joblib

joblib.dump(forest_reg, "my_model_50167.227.pkl") # my_model 뒤에 오차율을 적어놓는게 일반적
```

```
['my_model_50167.227.pkl']
```

> 코랩 페이지 왼쪽 파일을 눌러서 다운로드 가능



```python
# 그리드 탐색
from sklearn.model_selection import GridSearchCV

# 하이퍼 파라미터 딕셔너리
# 하이퍼 파라미터: 사람이 개입하여 모델이 각각의 알고리즘으로 인해 스스로 알아내는 것
# n_estimators: 최적의 나무 갯수를 보기 위함
# max_feature: 개수
# bootstrap: 부트스트랩 샘플링 유무
param_grid = [
              {"n_estimators": [3, 10, 30], "max_features":[2, 4, 6, 8]},
              {"bootstrap": [False], "n_estimators": [3, 10], "max_features": [2, 3, 4]},
]

# 사용할 모델
forest_reg = RandomForestRegressor()

# 하이퍼 파라미터를 찾기 위한 그리드서치 + 크로스 벨리데이션 설정
grid_search = GridSearchCV(forest_reg, param_grid, cv=5,
                           scoring='neg_mean_squared_error',
                           return_train_score=True)

# 훈련
grid_search.fit(housing_prepared, housing_labels)
```

```
GridSearchCV(cv=5, error_score=nan,
             estimator=RandomForestRegressor(bootstrap=True, ccp_alpha=0.0,
                                             criterion='mse', max_depth=None,
                                             max_features='auto',
                                             max_leaf_nodes=None,
                                             max_samples=None,
                                             min_impurity_decrease=0.0,
                                             min_impurity_split=None,
                                             min_samples_leaf=1,
                                             min_samples_split=2,
                                             min_weight_fraction_leaf=0.0,
                                             n_estimators=100, n_jobs=None,
                                             oob_score=False, random_state=None,
                                             verbose=0, warm_start=False),
             iid='deprecated', n_jobs=None,
             param_grid=[{'max_features': [2, 4, 6, 8],
                          'n_estimators': [3, 10, 30]},
                         {'bootstrap': [False], 'max_features': [2, 3, 4],
                          'n_estimators': [3, 10]}],
             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,
             scoring='neg_mean_squared_error', verbose=0)
```



```python
grid_search.best_params_ # 최고의 성능을 낸 하이퍼 파라미터

grid_search.best_estimator_ # 최고의 성능을 낸 추정기
```

```
RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',
                      max_depth=None, max_features=8, max_leaf_nodes=None,
                      max_samples=None, min_impurity_decrease=0.0,
                      min_impurity_split=None, min_samples_leaf=1,
                      min_samples_split=2, min_weight_fraction_leaf=0.0,
                      n_estimators=30, n_jobs=None, oob_score=False,
                      random_state=None, verbose=0, warm_start=False)
```



```python
res = grid_search.cv_results_

# 왼쪽: 오차율, 오른쪽: 오차를 낸 파라미터
for mean_score, params in zip(res["mean_test_score"], res["params"]):
  print(np.sqrt(-mean_score), params)
```

```
65339.3641874069 {'max_features': 2, 'n_estimators': 3}
56179.58151845636 {'max_features': 2, 'n_estimators': 10}
53169.53611743077 {'max_features': 2, 'n_estimators': 30}
60763.531392280456 {'max_features': 4, 'n_estimators': 3}
53308.428346825945 {'max_features': 4, 'n_estimators': 10}
51073.30956308354 {'max_features': 4, 'n_estimators': 30}
60931.51873664769 {'max_features': 6, 'n_estimators': 3}
53109.22709186974 {'max_features': 6, 'n_estimators': 10}
51083.521550980025 {'max_features': 6, 'n_estimators': 30}
59429.09860363291 {'max_features': 8, 'n_estimators': 3}
53225.40719728252 {'max_features': 8, 'n_estimators': 10}
50965.30970480886 {'max_features': 8, 'n_estimators': 30}
61876.47571701493 {'bootstrap': False, 'max_features': 2, 'n_estimators': 3}
55207.71750611235 {'bootstrap': False, 'max_features': 2, 'n_estimators': 10}
59929.83246806215 {'bootstrap': False, 'max_features': 3, 'n_estimators': 3}
53379.60666410668 {'bootstrap': False, 'max_features': 3, 'n_estimators': 10}
59750.92646520764 {'bootstrap': False, 'max_features': 4, 'n_estimators': 3}
52774.36758895914 {'bootstrap': False, 'max_features': 4, 'n_estimators': 10}
```



```python
final_model = grid_search.best_estimator_ # 최고의 성능을 낸 모델 가져오기

# 테스트 세트 준비
X_test = strat_test_set.drop("median_house_value", axis=1)
y_test = strat_test_set["median_house_value"].copy()

# 훈련 세트와 똑같이 변환기에 넣고 돌림
X_test_prepared = full_pipeline.transform(X_test)

# 예측과 오차를 확인하기
final_predictions = final_model.predict(X_test_prepared)

final_mse = mean_squared_error(y_test, final_predictions)
final_rmse = np.sqrt(final_mse)

print(final_rmse)
```

```
48916.27031932749
```

