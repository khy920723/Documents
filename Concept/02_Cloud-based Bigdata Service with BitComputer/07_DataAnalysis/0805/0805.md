# BeautifulSoup

```python
from bs4 import BeautifulSoup

def replace_newline(soup_html):
    br_to_newlines = soup_html.find_all("br")  #  <<-  **밑에 있는 문장의 결과물
    for br_to_newline in br_to_newlines:  # br 을 \n 으로 바꿔서 줄을 바꾸는 명령을 넣어준다.
        br_to_newline.replace_with("\n")
    return soup_html

f = open("C:\\Users\\BIT\\Desktop\\KHY\\7_DataAnalysis\\0805\\HTML_example3.html", encoding='utf-8')

html3 = f.read()
f.close()

soup = BeautifulSoup(html3, 'lxml')


title = soup.find('p', {"id": "title"})
contents = soup.find_all('p', {"id":"content"})

print(title.get_text(), '\n')

for content in contents:
    content1 = replace_newline(content)
    print(content1.get_text(), '\n')
```

```
D:\KHY\pycharm_workspace\exam01\venv\Scripts\python.exe D:/KHY/pycharm_workspace/exam01/0805.py
대한민국헌법 

제1조 
1.대한민국은 민주공화국이다.
2.대한민국의 주권은 국민에게 있고 모든 권력은 국민으로부터 나온다. 


Process finished with exit code 0

```

> Beautifulsoup 에서는 객체를 레퍼런스화 해서 참조하기 때문에 참조한 값을변화시키면 원본에도 영향을 줘서 변화시킴(Beautifulsoup 특징이므로 기억해놓을 것)



- TOP 50 사이트 가져오기

> requests 패키지 설치

```python
from bs4 import BeautifulSoup
import requests

url = 'https://www.alexa.com/topsites/countries/KR'

html_website_ranking = requests.get(url).text
soup_website_ranking = BeautifulSoup(html_website_ranking, 'lxml')

website_ranking = soup_website_ranking.select('p a')
# print(website_ranking[0:6])  #첫번째 값은 필요없다 는걸 결과값으로 알 수 있다.

website_ranking_site = [website_ranking_element.get_text()
                        for website_ranking_element in website_ranking[1:]]

print("[Top sites is South Korea]")
for k in range(len(website_ranking)-1):
    print("{0}: {1}".format(k + 1, website_ranking_site[k]))
```

```
D:\KHY\pycharm_workspace\exam01\venv\Scripts\python.exe D:/KHY/pycharm_workspace/exam01/0805.py
[Top sites is South Korea]
1: Google.com
2: Naver.com
3: Youtube.com
4: Daum.net
5: Tistory.com
6: Tmall.com
7: Google.co.kr
8: Kakao.com
9: Amazon.com
10: Facebook.com
11: Sohu.com
12: Qq.com
13: Namu.wiki
14: Coupang.com
15: Wikipedia.org
16: Netflix.com
17: Login.tmall.com
18: Taobao.com
19: 360.cn
20: Jd.com
21: Baidu.com
22: Dcinside.com
23: Microsoft.com
24: Yahoo.com
25: Pages.tmall.com
26: Gmarket.co.kr
27: Twitch.tv
28: Instagram.com
29: Apple.com
30: Sina.com.cn
31: Weibo.com
32: Nexon.com
33: Bing.com
34: Donga.com
35: Stackoverflow.com
36: Nate.com
37: Adobe.com
38: Yna.co.kr
39: 11st.co.kr
40: Office.com
41: Ruliweb.com
42: Ebay.com
43: Joins.com
44: Amazon.co.uk
45: Theepochtimes.com
46: Auction.co.kr
47: Inven.co.kr
48: Chosun.com
49: Afreecatv.com
50: Ppomppu.co.kr

Process finished with exit code 0

```



- pandas를 이용해서 가져오기

```python
from bs4 import BeautifulSoup
import requests
import pandas as pd

url = 'https://www.alexa.com/topsites/countries/KR'

html_website_ranking = requests.get(url).text
soup_website_ranking = BeautifulSoup(html_website_ranking, 'lxml')

website_ranking = soup_website_ranking.select('p a')
# print(website_ranking[0:6])  #첫번째 값은 필요없다 는걸 결과값으로 알 수 있다.

website_ranking_sites = [website_ranking_element.get_text()
                        for website_ranking_element in website_ranking[1:]]


website_ranking_dict = {'Website': website_ranking_sites}
df = pd.DataFrame(website_ranking_dict, columns=['Website'],
                  index=range(1,len(website_ranking_sites)+1))

print([df[0:6]])
```

```
D:\KHY\pycharm_workspace\exam01\venv\Scripts\python.exe D:/KHY/pycharm_workspace/exam01/0805.py
[       Website
1   Google.com
2    Naver.com
3  Youtube.com
4     Daum.net
5  Tistory.com
6    Tmall.com]

Process finished with exit code 0

```



- 네이버 뮤직 7월 3째주 top 50까지 제목 가져오기

```python
from bs4 import BeautifulSoup
import requests
import pandas as pd

url = 'https://music.naver.com/listen/history/index.nhn?type=TOTAL_V2&year=2020&month=07&week=3'

html_music = requests.get(url).text
soup_music = BeautifulSoup(html_music, 'lxml')

title = soup_music.select('a._title span.ellipsis')  #id 는 #   . 은 class 로 표현(약속)
#print(title[0:6])

titles = [title_element.get_text()
          for title_element in title[0:]]

# print("[Top Music]")
# for k in range(len(title)):
#     print("{0}: {1}".format(k + 1, titles[k]))   <<- 긁어오기

title_dict = {'Title': titles}
df = pd.DataFrame(title_dict, columns=['Title'],
                  index=range(1,len(titles)+1))  # pandas 이용해서
print(df)
```

```
D:\KHY\pycharm_workspace\exam01\venv\Scripts\python.exe D:/KHY/pycharm_workspace/exam01/0805.py
                              Title
1                         다시 여기 바닷가
2                       마리아 (Maria)
3                 How You Like That
4         여름 안에서 by 싹쓰리 (Feat. 황광희)
5             Summer Hate (Feat. 비)
6              보라빛 밤 (pporappippam)
7       에잇(Prod.&Feat. SUGA of BTS)
8                     Downtown Baby
9                           Dolphin
10                              아로하
11                 살짝 설렜어 (Nonstop)
12                     사랑하게 될 줄 알았어
13                          Monster
14                      MORE & MORE
15                  PLAY (Feat. 창모)
16        어떻게 이별까지 사랑하겠어, 널 사랑하는 거지
17                             아무노래
18                  Into the I-LAND
19                         Memories
20         흔들리는 꽃들 속에서 네 샴푸향이 느껴진거야
21                         Blueming
22                  좋은 사람 있으면 소개시켜줘
23                  Don't Start Now
24                           METEOR
25                           Psycho
26                     Dance Monkey
27                   덤더럼(Dumhdurum)
28                       화려하지 않은 고백
29                             OHIO
30                             처음처럼
31                             2002
32                          WANNABE
33                        Love poem
34    나비와 고양이 (Feat. 백현 (BAEKHYUN))
35                늦은 밤 너의 집 앞 골목길에서
36                               시작
37                        그대 고운 내사랑
38                Paris In The Rain
39  환상동화 (Secret Story of the Swan)
40                            너를 만나
41                       Rain On Me
42                     아직 너의 시간에 살아
43          어떻게 지내 (Prod. By VAN.C)
44                            Juice
45                               홀로
46                            Apple
47                     너에게 난, 나에게 넌
48                           FIESTA
49                              밤편지
50                 오늘따라 비가 와서 그런가 봐

Process finished with exit code 0

```



- 가수 이름 가져오기

```python
from bs4 import BeautifulSoup
import requests
import pandas as pd

url = 'https://music.naver.com/listen/history/index.nhn?type=TOTAL_V2&year=2020&month=07&week=3'

html_artist = requests.get(url).text
soup_artist = BeautifulSoup(html_artist, 'lxml')

artist_name = soup_artist.select('a._artist span.ellipsis')
#print(artist_name[0:6])

artist_names = [artist_name_element.get_text().replace('\r', '').replace('\n', '').replace('\t', '')
                for artist_name_element in artist_name[0:]]
# print("[Artist Name]")
# for k in range(len(artist_name)):
#     print("{0}: {1}".format(k + 1, artist_names[k]))

artist_dict = {'Name': artist_names}
df = pd.DataFrame(artist_dict,
                  columns=['Name'], index=range(1, len(artist_names)+1))
print(df)
```

```
D:\KHY\pycharm_workspace\exam01\venv\Scripts\python.exe D:/KHY/pycharm_workspace/exam01/0805.py
                  Name
1   싹쓰리(유두래곤, 린다G, 비룡)
2           화사(Hwa Sa)
3            BLACKPINK
4   싹쓰리(유두래곤, 린다G, 비룡)
5            지코 (ZICO)
6                   선미
7              아이유(IU)
8             블루(BLOO)
9     오마이걸(OH MY GIRL)
10                 조정석
11    오마이걸(OH MY GIRL)
12                 전미도
13         레드벨벳-아이린&슬기
14         TWICE(트와이스)
15                  청하
16        AKMU (악동뮤지션)
17           지코 (ZICO)
18             아이유(IU)
19            Maroon 5
20                 장범준
21             아이유(IU)
22            조이 (JOY)
23            Dua Lipa
24         창모(CHANGMO)
25   Red Velvet (레드벨벳)
26         Tones And I
27         에이핑크(Apink)
28         규현(KYUHYUN)
29               Crush
30  엠씨더맥스(M.C the MAX)
31          Anne-Marie
32            ITZY(있지)
33             아이유(IU)
34              볼빨간사춘기
35                  노을
36           가호 (Gaho)
37               어반자카파
38                Lauv
39        IZ*ONE(아이즈원)
40                  폴킴
41                 이수현
42                  오반
43               Lizzo
44                 이하이
45       여자친구(GFRIEND)
46             미도와 파라솔
47        IZ*ONE(아이즈원)
48             아이유(IU)
49                  솔지

Process finished with exit code 0

```



```python
from bs4 import BeautifulSoup
import requests
import pandas as pd

url = 'https://music.naver.com/listen/history/index.nhn?type=TOTAL_V2&year=2020&month=07&week=3'

html_artist = requests.get(url).text
soup_artist = BeautifulSoup(html_artist, 'lxml')

artist_name = soup_artist.select('td._artist a')
#print(artist_name[0:6])

artist_names = [artist_name_element.get_text().strip()  # 간단하게 \r \n \t 없애는 방법
                for artist_name_element in artist_name[0:]]
# print("[Artist Name]")
# for k in range(len(artist_name)):
#     print("{0}: {1}".format(k + 1, artist_names[k]))

artist_dict = {'Name': artist_names}
df = pd.DataFrame(artist_dict,
                  columns=['Name'], index=range(1, len(artist_names)+1))

print(df)
```

```
D:\KHY\pycharm_workspace\exam01\venv\Scripts\python.exe D:/KHY/pycharm_workspace/exam01/0805.py
                  Name
1   싹쓰리(유두래곤, 린다G, 비룡)
2           화사(Hwa Sa)
3            BLACKPINK
4   싹쓰리(유두래곤, 린다G, 비룡)
5            지코 (ZICO)
6                   선미
7              아이유(IU)
8             블루(BLOO)
9     오마이걸(OH MY GIRL)
10                 조정석
11    오마이걸(OH MY GIRL)
12                 전미도
13         레드벨벳-아이린&슬기
14         TWICE(트와이스)
15                  청하
16        AKMU (악동뮤지션)
17           지코 (ZICO)
18             아이유(IU)
19            Maroon 5
20                 장범준
21             아이유(IU)
22            조이 (JOY)
23            Dua Lipa
24         창모(CHANGMO)
25   Red Velvet (레드벨벳)
26         Tones And I
27         에이핑크(Apink)
28         규현(KYUHYUN)
29               Crush
30  엠씨더맥스(M.C the MAX)
31          Anne-Marie
32            ITZY(있지)
33             아이유(IU)
34              볼빨간사춘기
35                  노을
36           가호 (Gaho)
37               어반자카파
38                Lauv
39        IZ*ONE(아이즈원)
40                  폴킴
41           Lady Gaga
42                 이수현
43                  오반
44               Lizzo
45                 이하이
46       여자친구(GFRIEND)
47             미도와 파라솔
48        IZ*ONE(아이즈원)
49             아이유(IU)
50                  솔지

Process finished with exit code 0

```



- 제목 + 가수이름

```python
from bs4 import BeautifulSoup
import requests
import pandas as pd

# 아티스트
url = 'https://music.naver.com/listen/history/index.nhn?type=TOTAL_V2&year=2020&month=07&week=3'

html_artist = requests.get(url).text
soup_artist = BeautifulSoup(html_artist, 'lxml')

artist_name = soup_artist.select('td._artist a')

artist_names = [artist_name_element.get_text().strip()  # 간단하게 \r \n \t 없애는 방법
                for artist_name_element in artist_name[0:]]

artist_dict = {'Name': artist_names}
df = pd.DataFrame(artist_dict,
                  columns=['Name'], index=range(1, len(artist_names)+1))

# 제목
html_music = requests.get(url).text
soup_music = BeautifulSoup(html_music, 'lxml')

title = soup_music.select('a._title span.ellipsis')  #id 는 #   . 은 class 로 표현(약속)
#print(title[0:6])

titles = [title_element.get_text()
          for title_element in title[0:]]

title_dict = {'Title': titles}
df = pd.DataFrame(title_dict, columns=['Title'],
                  index=range(1,len(titles)+1))  # pandas 이용해서

for k in range(len(artist_names)):
    print("{0}: {1}/{2}".format(k+1, titles[k], artist_names[k]))
```

```
D:\KHY\pycharm_workspace\exam01\venv\Scripts\python.exe D:/KHY/pycharm_workspace/exam01/0805.py
1: 다시 여기 바닷가/싹쓰리(유두래곤, 린다G, 비룡)
2: 마리아 (Maria)/화사(Hwa Sa)
3: How You Like That/BLACKPINK
4: 여름 안에서 by 싹쓰리 (Feat. 황광희)/싹쓰리(유두래곤, 린다G, 비룡)
5: Summer Hate (Feat. 비)/지코 (ZICO)
6: 보라빛 밤 (pporappippam)/선미
7: 에잇(Prod.&Feat. SUGA of BTS)/아이유(IU)
8: Downtown Baby/블루(BLOO)
9: Dolphin/오마이걸(OH MY GIRL)
10: 아로하/조정석
11: 살짝 설렜어 (Nonstop)/오마이걸(OH MY GIRL)
12: 사랑하게 될 줄 알았어/전미도
13: Monster/레드벨벳-아이린&슬기
14: MORE & MORE/TWICE(트와이스)
15: PLAY (Feat. 창모)/청하
16: 어떻게 이별까지 사랑하겠어, 널 사랑하는 거지/AKMU (악동뮤지션)
17: 아무노래/지코 (ZICO)
18: Into the I-LAND/아이유(IU)
19: Memories/Maroon 5
20: 흔들리는 꽃들 속에서 네 샴푸향이 느껴진거야/장범준
21: Blueming/아이유(IU)
22: 좋은 사람 있으면 소개시켜줘/조이 (JOY)
23: Don't Start Now/Dua Lipa
24: METEOR/창모(CHANGMO)
25: Psycho/Red Velvet (레드벨벳)
26: Dance Monkey/Tones And I
27: 덤더럼(Dumhdurum)/에이핑크(Apink)
28: 화려하지 않은 고백/규현(KYUHYUN)
29: OHIO/Crush
30: 처음처럼/엠씨더맥스(M.C the MAX)
31: 2002/Anne-Marie
32: WANNABE/ITZY(있지)
33: Love poem/아이유(IU)
34: 나비와 고양이 (Feat. 백현 (BAEKHYUN))/볼빨간사춘기
35: 늦은 밤 너의 집 앞 골목길에서/노을
36: 시작/가호 (Gaho)
37: 그대 고운 내사랑/어반자카파
38: Paris In The Rain/Lauv
39: 환상동화 (Secret Story of the Swan)/IZ*ONE(아이즈원)
40: 너를 만나/폴킴
41: Rain On Me/Lady Gaga
42: 아직 너의 시간에 살아/이수현
43: 어떻게 지내 (Prod. By VAN.C)/오반
44: Juice/Lizzo
45: 홀로/이하이
46: Apple/여자친구(GFRIEND)
47: 너에게 난, 나에게 넌/미도와 파라솔
48: FIESTA/IZ*ONE(아이즈원)
49: 밤편지/아이유(IU)
50: 오늘따라 비가 와서 그런가 봐/솔지

Process finished with exit code 0

```

> pandas 로 가져온 결과물은 약간 오른쪽 정렬로 되어있는듯한 느낌을 받는다. (파이참에서 보여지는건 의미가 없음)
> 결국 데이터파일을 엑셀로 추출할거라 추출했을 당시 문제가 있다면 수정해야하지만, 그렇지 않을시에는 괜찮다.



- 네이버 top music 50 위까지의 노래제목과 가수이름을 메모장에 저장

```python
from bs4 import BeautifulSoup
import requests
import pandas as pd

# 파일 저장
file_name = ('C:\\Users\\BIT\\Desktop\\KHY\\7_DataAnalysis\\0805\\NaverMusicTop100.txt')  # 저장하고 싶은 장소 선정
f = open(file_name, 'w', encoding='utf-8')  # 파일, 쓰기전용, encoding utf-8: 유니코드 기반 언어표준


# 노래제목 추출
url = 'https://music.naver.com/listen/history/index.nhn?type=TOTAL_V2&year=2020&month=07&week=3'

html_music = requests.get(url).text
soup_music = BeautifulSoup(html_music, 'lxml')

title = soup_music.select('a._title span.ellipsis')  #id 는 #   . 은 class 로 표현(약속)

titles = [title_element.get_text()
          for title_element in title[0:]]

print("[Top Music]")
for k in range(len(title)):
    print("{0}: {1}".format(k + 1, titles[k]))


# 가수이름 추출
url = 'https://music.naver.com/listen/history/index.nhn?type=TOTAL_V2&year=2020&month=07&week=3'

html_artist = requests.get(url).text
soup_artist = BeautifulSoup(html_artist, 'lxml')

artist_name = soup_artist.select('td._artist a')

artist_names = [artist_name_element.get_text().strip()
                for artist_name_element in artist_name[0:]]
print("[Artist Name]")
for k in range(len(artist_name)):
    print("{0}: {1}".format(k + 1, artist_names[k]))


# 설정한 경로에 실제로 저장하는 코드
for k in range(len(artist_names)):
    f.write("{0}: {1}/{2}\n".format(k + 1, titles[k], artist_names[k]))
```

```
D:\KHY\pycharm_workspace\exam01\venv\Scripts\python.exe D:/KHY/pycharm_workspace/exam01/0805.py
[Top Music]
1: 다시 여기 바닷가
2: 마리아 (Maria)
3: How You Like That
4: 여름 안에서 by 싹쓰리 (Feat. 황광희)
5: Summer Hate (Feat. 비)
6: 보라빛 밤 (pporappippam)
7: 에잇(Prod.&Feat. SUGA of BTS)
8: Downtown Baby
9: Dolphin
10: 아로하
11: 살짝 설렜어 (Nonstop)
12: 사랑하게 될 줄 알았어
13: Monster
14: MORE & MORE
15: PLAY (Feat. 창모)
16: 어떻게 이별까지 사랑하겠어, 널 사랑하는 거지
17: 아무노래
18: Into the I-LAND
19: Memories
20: 흔들리는 꽃들 속에서 네 샴푸향이 느껴진거야
21: Blueming
22: 좋은 사람 있으면 소개시켜줘
23: Don't Start Now
24: METEOR
25: Psycho
26: Dance Monkey
27: 덤더럼(Dumhdurum)
28: 화려하지 않은 고백
29: OHIO
30: 처음처럼
31: 2002
32: WANNABE
33: Love poem
34: 나비와 고양이 (Feat. 백현 (BAEKHYUN))
35: 늦은 밤 너의 집 앞 골목길에서
36: 시작
37: 그대 고운 내사랑
38: Paris In The Rain
39: 환상동화 (Secret Story of the Swan)
40: 너를 만나
41: Rain On Me
42: 아직 너의 시간에 살아
43: 어떻게 지내 (Prod. By VAN.C)
44: Juice
45: 홀로
46: Apple
47: 너에게 난, 나에게 넌
48: FIESTA
49: 밤편지
50: 오늘따라 비가 와서 그런가 봐
[Artist Name]
1: 싹쓰리(유두래곤, 린다G, 비룡)
2: 화사(Hwa Sa)
3: BLACKPINK
4: 싹쓰리(유두래곤, 린다G, 비룡)
5: 지코 (ZICO)
6: 선미
7: 아이유(IU)
8: 블루(BLOO)
9: 오마이걸(OH MY GIRL)
10: 조정석
11: 오마이걸(OH MY GIRL)
12: 전미도
13: 레드벨벳-아이린&슬기
14: TWICE(트와이스)
15: 청하
16: AKMU (악동뮤지션)
17: 지코 (ZICO)
18: 아이유(IU)
19: Maroon 5
20: 장범준
21: 아이유(IU)
22: 조이 (JOY)
23: Dua Lipa
24: 창모(CHANGMO)
25: Red Velvet (레드벨벳)
26: Tones And I
27: 에이핑크(Apink)
28: 규현(KYUHYUN)
29: Crush
30: 엠씨더맥스(M.C the MAX)
31: Anne-Marie
32: ITZY(있지)
33: 아이유(IU)
34: 볼빨간사춘기
35: 노을
36: 가호 (Gaho)
37: 어반자카파
38: Lauv
39: IZ*ONE(아이즈원)
40: 폴킴
41: Lady Gaga
42: 이수현
43: 오반
44: Lizzo
45: 이하이
46: 여자친구(GFRIEND)
47: 미도와 파라솔
48: IZ*ONE(아이즈원)
49: 아이유(IU)
50: 솔지

Process finished with exit code 0

```

```
1: 다시 여기 바닷가/싹쓰리(유두래곤, 린다G, 비룡)
2: 마리아 (Maria)/화사(Hwa Sa)
3: How You Like That/BLACKPINK
4: 여름 안에서 by 싹쓰리 (Feat. 황광희)/싹쓰리(유두래곤, 린다G, 비룡)
5: Summer Hate (Feat. 비)/지코 (ZICO)
6: 보라빛 밤 (pporappippam)/선미
7: 에잇(Prod.&Feat. SUGA of BTS)/아이유(IU)
8: Downtown Baby/블루(BLOO)
9: Dolphin/오마이걸(OH MY GIRL)
10: 아로하/조정석
11: 살짝 설렜어 (Nonstop)/오마이걸(OH MY GIRL)
12: 사랑하게 될 줄 알았어/전미도
13: Monster/레드벨벳-아이린&슬기
14: MORE & MORE/TWICE(트와이스)
15: PLAY (Feat. 창모)/청하
16: 어떻게 이별까지 사랑하겠어, 널 사랑하는 거지/AKMU (악동뮤지션)
17: 아무노래/지코 (ZICO)
18: Into the I-LAND/아이유(IU)
19: Memories/Maroon 5
20: 흔들리는 꽃들 속에서 네 샴푸향이 느껴진거야/장범준
21: Blueming/아이유(IU)
22: 좋은 사람 있으면 소개시켜줘/조이 (JOY)
23: Don't Start Now/Dua Lipa
24: METEOR/창모(CHANGMO)
25: Psycho/Red Velvet (레드벨벳)
26: Dance Monkey/Tones And I
27: 덤더럼(Dumhdurum)/에이핑크(Apink)
28: 화려하지 않은 고백/규현(KYUHYUN)
29: OHIO/Crush
30: 처음처럼/엠씨더맥스(M.C the MAX)
31: 2002/Anne-Marie
32: WANNABE/ITZY(있지)
33: Love poem/아이유(IU)
34: 나비와 고양이 (Feat. 백현 (BAEKHYUN))/볼빨간사춘기
35: 늦은 밤 너의 집 앞 골목길에서/노을
36: 시작/가호 (Gaho)
37: 그대 고운 내사랑/어반자카파
38: Paris In The Rain/Lauv
39: 환상동화 (Secret Story of the Swan)/IZ*ONE(아이즈원)
40: 너를 만나/폴킴
41: Rain On Me/Lady Gaga
42: 아직 너의 시간에 살아/이수현
43: 어떻게 지내 (Prod. By VAN.C)/오반
44: Juice/Lizzo
45: 홀로/이하이
46: Apple/여자친구(GFRIEND)
47: 너에게 난, 나에게 넌/미도와 파라솔
48: FIESTA/IZ*ONE(아이즈원)
49: 밤편지/아이유(IU)
50: 오늘따라 비가 와서 그런가 봐/솔지

```

> NaverMusicTop100.txt



- 파이썬싸이트에서 파이썬로고 내려받아보기

```python
from bs4 import BeautifulSoup
import requests
import pandas as pd
import os

url = 'https://www.python.org/static/img/python-logo.png'
html_image = requests.get(url)
image_file_name = os.path.basename(url)
folder = 'C:\\Users\\BIT\\Desktop\\KHY\\7_DataAnalysis\\0805\\ImageDownload'

if not os.path.exists(folder):
    os.makedirs(folder)

image_path = os.path.join(folder, image_file_name)

imageFile = open(image_path, 'wb')
# 이미지 데이터를 10000000 바이트씩 나눠서 저장
chunk_size = 1000000

for chunk in html_image.iter_content(chunk_size):
    imageFile.write(chunk)

imageFile.close()
```





## 실습

- 선택한 사이트에서 이미지 내려받기

```python
from bs4 import BeautifulSoup
import requests
import pandas as pd
import os


# 사이트명, 저장폴더 지정
def get_image_url(url):
    # url 을 인자값으로 받는 get_image_url 함수를 만든다.
    html_image_url = requests.get(url).text
    # requests 라이브러리 get 함수를 이용해 인터넷에 연결해 url 을 가져오는데,
    # text 를 이용해서 관련 html 코드를 전부 html_image_url 에 할당한다.
    soup_image_url = BeautifulSoup(html_image_url, "lxml")
    # BeautifulSoup 라이브러리로 html_image_url 에 있는 코드를 해석한다.
    # BeautifulSoup은 html 코드를 Python이 이해하는 객체 구조로 변환하는 Parsing을 맡고 있고,
    # 이 라이브러리를 이용해 우리는 제대로 된 '의미있는' 정보를 추출해 낼 수 있다.
    image_elements = soup_image_url.select(('picture img'))
    # '검사' 에서 얻을 수 있는 공통된 코드인자로 select 한 url 들을 image_elements 에 할당한다.
    if image_elements != None:
        # 만약 image_elements 가 None 이 아니라면
        image_urls = []
        # image_urls 라는 리스트를 만든다.
        for image_element in image_elements:
            # image_elements 의 url들을 image_element 에 하나씩 넣고
            image_urls.append(image_element.get('data-src'))
            #image_urls에 image_element 에서 get 메서드로 얻은 data-src 가 포함한 url 주소를 append 로 뒤에서부터 넣어준다.
        return image_urls
            # return 값으로 image_urls 준다.
    else:
        # 만약 image_elements 가 None 이라면
        return None
        # return 값 역시 None 이다.


# 폴더를 지정해 이미지 주소에서 이미지 내려받기
def download_image(img_folder, img_url):
    # download_image 함수를 만들고 매개변수로 img_folder 와 img_url 을 할당한다.
    if (img_url != None):
        # 만약 img_url 이 None 이 아니라면
        html_image = requests.get(img_url)
        # requests로 인터넷에 연결하여 get 함수를 이용해 img_url 에 있는 url 을 html_image 에 할당한다.

        image_file = open(os.path.join(img_folder, os.path.basename(img_url)), 'wb')
        # os.path.basename(URL)는 웹사이트나 폴더가 포함된 파일명에서 파일명만 분리
        # os 라이브러리의 path 모듈, basename 을 이용해 img_url 의 url 중 파일명만 분리하고,
        # img_folder 와 join 함수로 분리된 파일명을 열린 공간(open) 에 즉, image_file 에 할당한다.

        chunk_size = 1000000
        # 보내줄 크기를 정한다.
        for chunk in html_image.iter_content(chunk_size):
            # img_url 에 있는 url 이 할당되어 있는 html_image 을 chunk_size 로 iterator 적용, 하나하나 분리해서
            # chunk 에 넣는다.
            image_file.write(chunk)
            # image_file 에 chunk 로 분리된 파일을 넣어준다. (*******여기서 파일은 이미 받아짐)
            image_file.close()
        print("이미지 파일명: '{0}.내려받기 완료!".format(os.path.basename(img_url)))
                                                # 내려받는거 파일명으로 알려주기
    else:
        print("내려받을 이미지가 없습니다.")


url = 'https://picjumbo.com/free-stock-photos/nature/'
figure_folder = "C:\\Users\\BIT\\Desktop\\KHY\\7_DataAnalysis\\0805\\ImageDownload"

picjumbo_image_urls = get_image_url(url) #이미지 파일의 주소 가져오기
num_of_download_image = 7 # 내려받을 이미지 개수 지정
# num_of_download_image = len(picjumbo_image_urls) # 전체 이미지를 내려받으려면
for k in range(num_of_download_image):
    # 7개의 이미지를 내려받아 k 에 하나씩 넣고
    download_image(figure_folder, picjumbo_image_urls[k])
    # 위에 만들어 놓은 download_image 함수 의 인자로 적용되어 실행됨
print("===============================")
print("선택한 모든 이미지 내려받기 완료")
```

```
D:\KHY\pycharm_workspace\exam01\venv\Scripts\python.exe D:/KHY/pycharm_workspace/exam01/0805.py
이미지 파일명: 'D0100403-1080x1620.jpg.내려받기 완료!
이미지 파일명: 'DSC06401-1080x720.jpg.내려받기 완료!
이미지 파일명: 'D0100448-1080x720.jpg.내려받기 완료!
이미지 파일명: 'DSC00128-1080x720.jpg.내려받기 완료!
이미지 파일명: 'DSC07667-1080x1620.jpg.내려받기 완료!
이미지 파일명: 'DSC09423-1080x720.jpg.내려받기 완료!
이미지 파일명: 'DSC07564-1080x720.jpg.내려받기 완료!
===============================
선택한 모든 이미지 내려받기 완료

Process finished with exit code 0

```

