# 데이터 분석 예제 (529p~)

> 깃허브 저장소
>
> github.com/wesm/pydata-book 의 데이터셋 다운로드



### Bit.ly의 1.USA.gov 데이터

> 파이썬 콘솔 사용

```
path = "C:\\Users\\BIT\\Desktop\\KHY\\7_DataAnalysis\\0806\\pydata-book-2nd-edition\\datasets\\bitly_usagov\\example.txt"
open(path).readline()
'{ "a": "Mozilla\\/5.0 (Windows NT 6.1; WOW64) AppleWebKit\\/535.11 (KHTML, like Gecko) Chrome\\/17.0.963.78 Safari\\/535.11", "c": "US", "nk": 1, "tz": "America\\/New_York", "gr": "MA", "g": "A6qOVH", "h": "wfLQtf", "l": "orofrog", "al": "en-US,en;q=0.8", "hh": "1.usa.gov", "r": "http:\\/\\/www.facebook.com\\/l\\/7AQEFzjSi\\/1.usa.gov\\/wfLQtf", "u": "http:\\/\\/www.ncbi.nlm.nih.gov\\/pubmed\\/22415991", "t": 1331923247, "hc": 1331822918, "cy": "Danvers", "ll": [ 42.576698, -70.954903 ] }\n'

```

```
import json
path = "C:\\Users\\BIT\\Desktop\\KHY\\7_DataAnalysis\\0806\\pydata-book-2nd-edition\\datasets\\bitly_usagov\\example.txt"
records = [json.loads(line) for line in open(path, encoding="utf-8")]
records[0]
{'a': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.11 (KHTML, like Gecko) Chrome/17.0.963.78 Safari/535.11', 'c': 'US', 'nk': 1, 'tz': 'America/New_York', 'gr': 'MA', 'g': 'A6qOVH', 'h': 'wfLQtf', 'l': 'orofrog', 'al': 'en-US,en;q=0.8', 'hh': '1.usa.gov', 'r': 'http://www.facebook.com/l/7AQEFzjSi/1.usa.gov/wfLQtf', 'u': 'http://www.ncbi.nlm.nih.gov/pubmed/22415991', 't': 1331923247, 'hc': 1331822918, 'cy': 'Danvers', 'll': [42.576698, -70.954903]}

```

> 데이터 불러오기



- 순수 파이썬으로 표준시간대 세어보기

```python
import json

path = "C:\\Users\\BIT\\Desktop\\KHY\\7_DataAnalysis\\0806\\pydata-book-2nd-edition\\datasets\\bitly_usagov\\example.txt"
records = [json.loads(line) for line in open(path, encoding="utf-8")]

time_zones = [rec['tz'] for rec in records]  # tz필드: 표준시간대, 리스트 표기법
print(time_zones)
```

```
D:\KHY\pycharm_workspace\exam01\venv\Scripts\python.exe D:/KHY/pycharm_workspace/exam01/0806.py
Traceback (most recent call last):
  File "D:/KHY/pycharm_workspace/exam01/0806.py", line 6, in <module>
    time_zones = [rec['tz'] for rec in records]
  File "D:/KHY/pycharm_workspace/exam01/0806.py", line 6, in <listcomp>
    time_zones = [rec['tz'] for rec in records]
KeyError: 'tz'

Process finished with exit code 1

```

> records의 아이템이 모두 표준시간대 필드를 가지고 있는 것은 아니여서 에러 발생



```python
import json

path = "C:\\Users\\BIT\\Desktop\\KHY\\7_DataAnalysis\\0806\\pydata-book-2nd-edition\\datasets\\bitly_usagov\\example.txt"
records = [json.loads(line) for line in open(path, encoding="utf-8")]

time_zones = [rec['tz'] for rec in records if 'tz' in rec]  # if 'tz' in rec를 리스트 표기법 뒤에 추가하여 tz 필드가 있는 지 검사
print(time_zones[:10])
```

```
데이터 결과가 길어서 생략
```

> 상위 10개의 표준시간대 데이터 중 몇 개는 필드가 비어있음



```python
import json
from collections import defaultdict

path = "C:\\Users\\BIT\\Desktop\\KHY\\7_DataAnalysis\\0806\\pydata-book-2nd-edition\\datasets\\bitly_usagov\\example.txt"
records = [json.loads(line) for line in open(path, encoding="utf-8")]

time_zones = [rec['tz'] for rec in records if 'tz' in rec]

"""
# 기존 코드
def get_counts(sequence):
    counts = {}  # 빈 딕셔너리
    for x in sequence:
        if x in counts:
            counts[x] += 1
        else:
            counts[x] = 1
    return counts
"""
def get_counts(sequence):
    counts = defaultdict(int)  # 값이 0으로 초기화
    for x in sequence:
        counts[x] += 1
    return counts


counts = get_counts(time_zones)
print(counts['America/New_York'])
print(len(time_zones))
```

```
D:\KHY\pycharm_workspace\exam01\venv\Scripts\python.exe D:/KHY/pycharm_workspace/exam01/0806.py
1251
3440

Process finished with exit code 0

```

> 로직을 함수로 만들고 이 함수에 time_zones 리스트를 넘겨서 사용



```python
import json
from collections import defaultdict

path = "C:\\Users\\BIT\\Desktop\\KHY\\7_DataAnalysis\\0806\\pydata-book-2nd-edition\\datasets\\bitly_usagov\\example.txt"
records = [json.loads(line) for line in open(path, encoding="utf-8")]

time_zones = [rec['tz'] for rec in records if 'tz' in rec]

def get_counts(sequence):
    counts = defaultdict(int)  # 값이 0으로 초기화
    for x in sequence:
        counts[x] += 1
    return counts

def top_counts(count_dict, n=10):
    value_key_pairs = [(count, tz) for tz, count in count_dict.items()]
    value_key_pairs.sort()
    return value_key_pairs[-n:]

counts = get_counts(time_zones)
print(top_counts(counts))
```

```
D:\KHY\pycharm_workspace\exam01\venv\Scripts\python.exe D:/KHY/pycharm_workspace/exam01/0806.py
[(33, 'America/Sao_Paulo'), (35, 'Europe/Madrid'), (36, 'Pacific/Honolulu'), (37, 'Asia/Tokyo'), (74, 'Europe/London'), (191, 'America/Denver'), (382, 'America/Los_Angeles'), (400, 'America/Chicago'), (521, ''), (1251, 'America/New_York')]

Process finished with exit code 0

```

> 상위 10개의 표준 시간대



```python
import json
from collections import Counter

path = "C:\\Users\\BIT\\Desktop\\KHY\\7_DataAnalysis\\0806\\pydata-book-2nd-edition\\datasets\\bitly_usagov\\example.txt"
records = [json.loads(line) for line in open(path, encoding="utf-8")]

time_zones = [rec['tz'] for rec in records if 'tz' in rec]


counts = Counter(time_zones)
print(counts.most_common(10))

```

```
D:\KHY\pycharm_workspace\exam01\venv\Scripts\python.exe D:/KHY/pycharm_workspace/exam01/0806.py
[('America/New_York', 1251), ('', 521), ('America/Chicago', 400), ('America/Los_Angeles', 382), ('America/Denver', 191), ('Europe/London', 74), ('Asia/Tokyo', 37), ('Pacific/Honolulu', 36), ('Europe/Madrid', 35), ('America/Sao_Paulo', 33)]

Process finished with exit code 0

```

> collections.Counter 클래스를 이용한 코드



- pandas로 표준시간대 세어보기

```python
import json
import pandas as pd

path = "C:\\Users\\BIT\\Desktop\\KHY\\7_DataAnalysis\\0806\\pydata-book-2nd-edition\\datasets\\bitly_usagov\\example.txt"
records = [json.loads(line) for line in open(path, encoding="utf-8")]

frame = pd.DataFrame(records)  # 레코드가 담긴 리스트를 pandas.Dataframe에 넘김
frame.info()
print('----------------------')
print(frame['tz'][:10])
```

```
D:\KHY\pycharm_workspace\exam01\venv\Scripts\python.exe D:/KHY/pycharm_workspace/exam01/0806.py
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 3560 entries, 0 to 3559
Data columns (total 18 columns):
 #   Column       Non-Null Count  Dtype  
---  ------       --------------  -----  
 0   a            3440 non-null   object 
 1   c            2919 non-null   object 
 2   nk           3440 non-null   float64
 3   tz           3440 non-null   object 
 4   gr           2919 non-null   object 
 5   g            3440 non-null   object 
 6   h            3440 non-null   object 
 7   l            3440 non-null   object 
 8   al           3094 non-null   object 
 9   hh           3440 non-null   object 
 10  r            3440 non-null   object 
 11  u            3440 non-null   object 
 12  t            3440 non-null   float64
 13  hc           3440 non-null   float64
 14  cy           2919 non-null   object 
 15  ll           2919 non-null   object 
 16  _heartbeat_  120 non-null    float64
 17  kw           93 non-null     object 
dtypes: float64(4), object(14)
memory usage: 500.8+ KB
----------------------
0     America/New_York
1       America/Denver
2     America/New_York
3    America/Sao_Paulo
4     America/New_York
5     America/New_York
6        Europe/Warsaw
7                     
8                     
9                     
Name: tz, dtype: object

Process finished with exit code 0

```

> frame의 출력 결과는 거대한 DataFrame 객체의 요약 정보임



```python
import json
import pandas as pd

path = "C:\\Users\\BIT\\Desktop\\KHY\\7_DataAnalysis\\0806\\pydata-book-2nd-edition\\datasets\\bitly_usagov\\example.txt"
records = [json.loads(line) for line in open(path, encoding="utf-8")]

frame = pd.DataFrame(records)

tz_counts = frame['tz'].value_counts()
print(tz_counts[:10])
```

```
D:\KHY\pycharm_workspace\exam01\venv\Scripts\python.exe D:/KHY/pycharm_workspace/exam01/0806.py
America/New_York       1251
                        521
America/Chicago         400
America/Los_Angeles     382
America/Denver          191
Europe/London            74
Asia/Tokyo               37
Pacific/Honolulu         36
Europe/Madrid            35
America/Sao_Paulo        33
Name: tz, dtype: int64

Process finished with exit code 0

```

> Series 객체를 value_couts() 메서드를 이용하여 시간대를 셈



```python
import json
import pandas as pd
import seaborn as sns
from matplotlib import pyplot as plt

path = "C:\\Users\\BIT\\Desktop\\KHY\\7_DataAnalysis\\0806\\pydata-book-2nd-edition\\datasets\\bitly_usagov\\example.txt"
records = [json.loads(line) for line in open(path, encoding="utf-8")]

frame = pd.DataFrame(records)

clean_tz = frame['tz'].fillna('Missing')  # fill() 메서드로 빠진 값 대체
clean_tz[clean_tz == ''] = 'Unknown'  # 불리언 배열 색인을 이용해 비어있는 값 대체
tz_counts = clean_tz.value_counts()
print(tz_counts[:10])

subset = tz_counts[:10]
sns.barplot(y=subset.index, x=subset.values)  # 수평 막대 그래프
plt.show()
```

```
D:\KHY\pycharm_workspace\exam01\venv\Scripts\python.exe D:/KHY/pycharm_workspace/exam01/0806.py
America/New_York       1251
Unknown                 521
America/Chicago         400
America/Los_Angeles     382
America/Denver          191
Missing                 120
Europe/London            74
Asia/Tokyo               37
Pacific/Honolulu         36
Europe/Madrid            35
Name: tz, dtype: int64

Process finished with exit code 0

```

> matplotlib 라이브러로리 데이터 그래프 그리기



```python
import json
import pandas as pd
import numpy as np
import seaborn as sns
from matplotlib import pyplot as plt

path = "C:\\Users\\BIT\\Desktop\\KHY\\7_DataAnalysis\\0806\\pydata-book-2nd-edition\\datasets\\bitly_usagov\\example.txt"
records = [json.loads(line) for line in open(path, encoding="utf-8")]

frame = pd.DataFrame(records)

# a 필드에는 URL 단축을 실행하는 브라우저, 단말기, 애플리케이션에 대한 정보(User Agent 문자열)가 들어있음
print(frame['a'][1])
print(frame['a'][50])
print(frame['a'][51][:51])  # 긴 문자열
print('----------------')

# 문자열에서 첫 번째 토큰을 잘라내서 사용자 행동에 대한 또 다른 개요 만듦
results = pd.Series([x.split()[0] for x in frame.a.dropna()])
print(results[:5])
print('----------------')
print(results.value_counts()[:8])
print('----------------')

# 표준시간대 순위표를 윈도우 사용자와 비윈도우 사용자 그룹으로 나누기
cframe = frame[frame.a.notnull()]  # agent값이 없는 데이터 제외
cframe['os'] = np.where(cframe['a'].str.contains('Windows'), 
                        'Windows', 'Not Windows')  # 각 로우가 윈도우인 지 아닌 지 검사
print(cframe['os'][:5])  # SettingWithCopyWarning이 뜨지만 무시(loc로 접근하는게 낫다는 주의)

print('----------------')

# 표준시간대와 운영체제 기준으로 데이터를 그룹으로 묶음
by_tz_os = cframe.groupby(['tz', 'os'])
agg_counts = by_tz_os.size().unstack().fillna(0)  # size()로 그룹별 합계 계산, 결과는 unstack()으로 표로 재배치
print(agg_counts)
print('----------------')

# 전체 표준시간대의 순위
indexer = agg_counts.sum(1).argsort()  # argsort(): 가상의 공간에서 sorting 시킴(원본 훼손하지 않음)
print(indexer)
print('----------------')

# take()를 사용해 로우를 정렬된 순서 그대로 선택 후 마지막 10개 로우(가장 큰 값)만 잘라냄
# 기존 코드
count_subset = agg_counts.take(indexer[-10:])
print(count_subset)
print('----------------')
"""
# pandas에서 nlargest() 메서드로 기존 코드 구현 가능
print(agg_counts.sum(1).nlargest(10))
"""

# 중첩 막대그래프로 만들기
count_subset = count_subset.stack()
count_subset.name = 'total'
count_subset = count_subset.reset_index()
print(count_subset[:10])

sns.barplot(x='total', y='tz', hue='os', data=count_subset)
plt.show()


# 각 로우에서 총합을 1로 정규화한 후 그래프를 그려 상대 비율 확인
def norm_total(group):
    group['normed_total'] = group.total / group.total.sum()
    return group

results = count_subset.groupby('tz').apply(norm_total)
sns.barplot(x='normed_total', y='tz', hue='os', data=results)
plt.show()


# groubby와 transform 메서드를 사용하여 정규합 계산
g = count_subset.groupby('tz')
results2 = count_subset.total / g.total.transform('sum')
sns.barplot(x='normed_total', y='tz', hue='os', data=results2)  # 이 부분이 에러뜸
plt.show()
```

```
D:\KHY\pycharm_workspace\exam01\venv\Scripts\python.exe D:/KHY/pycharm_workspace/exam01/0806.py
GoogleMaps/RochesterNY
Mozilla/5.0 (Windows NT 5.1; rv:10.0.2) Gecko/20100101 Firefox/10.0.2
Mozilla/5.0 (Linux; U; Android 2.2.2; en-us; LG-P92
----------------
0               Mozilla/5.0
1    GoogleMaps/RochesterNY
2               Mozilla/4.0
3               Mozilla/5.0
4               Mozilla/5.0
dtype: object
----------------
Mozilla/5.0                 2594
Mozilla/4.0                  601
GoogleMaps/RochesterNY       121
Opera/9.80                    34
TEST_INTERNET_AGENT           24
GoogleProducer                21
Mozilla/6.0                    5
BlackBerry8520/5.0.0.681       4
dtype: int64
----------------
0        Windows
1    Not Windows
2        Windows
3    Not Windows
4        Windows
Name: os, dtype: object
----------------
D:/KHY/pycharm_workspace/exam01/0806.py:28: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  'Windows', 'Not Windows')  # 각 로우가 윈도우인 지 아닌 지 검사
os                   Not Windows  Windows
tz                                       
                           245.0    276.0
Africa/Cairo                 0.0      3.0
Africa/Casablanca            0.0      1.0
Africa/Ceuta                 0.0      2.0
Africa/Johannesburg          0.0      1.0
...                          ...      ...
Europe/Volgograd             0.0      1.0
Europe/Warsaw                1.0     15.0
Europe/Zurich                4.0      0.0
Pacific/Auckland             3.0      8.0
Pacific/Honolulu             0.0     36.0

[97 rows x 2 columns]
----------------
tz
                       24
Africa/Cairo           20
Africa/Casablanca      21
Africa/Ceuta           92
Africa/Johannesburg    87
                       ..
Europe/Volgograd       15
Europe/Warsaw          22
Europe/Zurich          12
Pacific/Auckland        0
Pacific/Honolulu       29
Length: 97, dtype: int64
----------------
os                   Not Windows  Windows
tz                                       
America/Sao_Paulo           13.0     20.0
Europe/Madrid               16.0     19.0
Pacific/Honolulu             0.0     36.0
Asia/Tokyo                   2.0     35.0
Europe/London               43.0     31.0
America/Denver             132.0     59.0
America/Los_Angeles        130.0    252.0
America/Chicago            115.0    285.0
                           245.0    276.0
America/New_York           339.0    912.0
----------------
                  tz           os  total
0  America/Sao_Paulo  Not Windows   13.0
1  America/Sao_Paulo      Windows   20.0
2      Europe/Madrid  Not Windows   16.0
3      Europe/Madrid      Windows   19.0
4   Pacific/Honolulu  Not Windows    0.0
5   Pacific/Honolulu      Windows   36.0
6         Asia/Tokyo  Not Windows    2.0
7         Asia/Tokyo      Windows   35.0
8      Europe/London  Not Windows   43.0
9      Europe/London      Windows   31.0
Traceback (most recent call last):
  File "D:/KHY/pycharm_workspace/exam01/0806.py", line 77, in <module>
    sns.barplot(x='normed_total', y='tz', hue='os', data=results2)  # 이 부분이 에러뜸
  File "D:\KHY\pycharm_workspace\exam01\venv\lib\site-packages\seaborn\categorical.py", line 3147, in barplot
    errcolor, errwidth, capsize, dodge)
  File "D:\KHY\pycharm_workspace\exam01\venv\lib\site-packages\seaborn\categorical.py", line 1603, in __init__
    order, hue_order, units)
  File "D:\KHY\pycharm_workspace\exam01\venv\lib\site-packages\seaborn\categorical.py", line 152, in establish_variables
    raise ValueError(err)
ValueError: Could not interpret input 'normed_total'

Process finished with exit code 1

```



### MovieLens의 영화 평점 데이터

```python
import pandas as pd

# 출력되는 내용 줄이기
pd.options.display.max_rows = 10

unames = ['user_id', 'gender', 'age', 'occupation', 'zip']
users = pd.read_table('C:\\Users\\BIT\\Desktop\\KHY\\7_DataAnalysis\\0806\\pydata-book-2nd-edition\\datasets\\movielens\\users.dat',
                      sep='::', names=unames, engine='python')

rnames = ['user_id', 'movie_id', 'rating', 'timestamp']
ratings = pd.read_table('C:\\Users\\BIT\\Desktop\\KHY\\7_DataAnalysis\\0806\\pydata-book-2nd-edition\\datasets\\movielens\\ratings.dat',
                      sep='::', header=None, names=rnames, engine='python')

mnames = ['movie_id', 'title', 'genres']
movies = pd.read_table('C:\\Users\\BIT\\Desktop\\KHY\\7_DataAnalysis\\0806\\pydata-book-2nd-edition\\datasets\\movielens\\movies.dat',
                      sep='::', header=None, names=mnames, engine='python')

print(users[:5])
print('---------')
print(ratings[:5])
print('---------')
print(movies[:5])
```

```
D:\KHY\pycharm_workspace\exam01\venv\Scripts\python.exe D:/KHY/pycharm_workspace/exam01/0806.py
   user_id gender  age  occupation    zip
0        1      F    1          10  48067
1        2      M   56          16  70072
2        3      M   25          15  55117
3        4      M   45           7  02460
4        5      M   25          20  55455
---------
   user_id  movie_id  rating  timestamp
0        1      1193       5  978300760
1        1       661       3  978302109
2        1       914       3  978301968
3        1      3408       4  978300275
4        1      2355       5  978824291
---------
   movie_id                               title                        genres
0         1                    Toy Story (1995)   Animation|Children's|Comedy
1         2                      Jumanji (1995)  Adventure|Children's|Fantasy
2         3             Grumpier Old Men (1995)                Comedy|Romance
3         4            Waiting to Exhale (1995)                  Comedy|Drama
4         5  Father of the Bride Part II (1995)                        Comedy

Process finished with exit code 0

```

> 데이터 확인

> 나이와 직업은 실제 값이 아니라 그룹을 가리키는 코드 번호이며 데이터셋에 있는 README 파일에 해당 코드에 대한 설명 들어있음



```python
import pandas as pd

# 출력되는 내용 줄이기
pd.options.display.max_rows = 10

unames = ['user_id', 'gender', 'age', 'occupation', 'zip']
users = pd.read_table('C:\\Users\\BIT\\Desktop\\KHY\\7_DataAnalysis\\0806\\pydata-book-2nd-edition\\datasets\\movielens\\users.dat',
                      sep='::', names=unames, engine='python')

rnames = ['user_id', 'movie_id', 'rating', 'timestamp']
ratings = pd.read_table('C:\\Users\\BIT\\Desktop\\KHY\\7_DataAnalysis\\0806\\pydata-book-2nd-edition\\datasets\\movielens\\ratings.dat',
                      sep='::', header=None, names=rnames, engine='python')

mnames = ['movie_id', 'title', 'genres']
movies = pd.read_table('C:\\Users\\BIT\\Desktop\\KHY\\7_DataAnalysis\\0806\\pydata-book-2nd-edition\\datasets\\movielens\\movies.dat',
                      sep='::', header=None, names=mnames, engine='python')


# 모든 데이터를 하나의 테이블로 병합하여 계산
data = pd.merge(pd.merge(ratings, users), movies)  # pandas의 merge()를 이용해 ratings 테이블과 users 테이블을 병합하고 그 결과를 다시 movies 테이블과 병합
print(data)  # pandas는 병합하려는 두 테이블에서 중복되는 컬럼의 이름을 키로 사용
print('-------------------')
print(data.iloc[0])
print('-------------------')


# 성별에 따른 각 영화의 평균 평점
mean_ratings = data.pivot_table('rating', index='title',
                                columns='gender', aggfunc='mean')  # pivot_table()메서드 사용
print(mean_ratings[:5])  # 매 로우마다 성별에 따른 평균 영화 평점 정보를 담고 있는 DataFrame 객체가 생성됨
print('-------------------')


# 250건 이상의 평점 정보가 있는 영화 추리기
ratings_by_title = data.groupby('title').size()  # 영화 제목으로 그룹화 후 size()를 사용하여 제목별 평점 정보 건수를 Series 객체로 얻어냄
print(ratings_by_title[:10])
print('-------------------')
active_titles = ratings_by_title.index[ratings_by_title >= 250]
print(active_titles)
print('-------------------')


# 250건 이상의 평점 정보가 있는 영화에 대한 색인 사용
mean_ratings = mean_ratings.loc[active_titles]  # mean_ratings에서 항목을 선택하기 위해 사용
print(mean_ratings)
print('-------------------')


# 여성에게 높은 평점을 받은 영화목록을 확인하기 위해 F 컬럼 내림차순 정렬
top_female_ratings = mean_ratings.sort_values(by='F', ascending=False)
print(top_female_ratings)
print('-------------------')
```

```
D:\KHY\pycharm_workspace\exam01\venv\Scripts\python.exe D:/KHY/pycharm_workspace/exam01/0806.py
         user_id  ...                genres
0              1  ...                 Drama
1              2  ...                 Drama
2             12  ...                 Drama
3             15  ...                 Drama
4             17  ...                 Drama
...          ...  ...                   ...
1000204     5949  ...           Documentary
1000205     5675  ...                 Drama
1000206     5780  ...                 Drama
1000207     5851  ...  Comedy|Drama|Western
1000208     5938  ...           Documentary

[1000209 rows x 10 columns]
-------------------
user_id                                            1
movie_id                                        1193
rating                                             5
timestamp                                  978300760
gender                                             F
age                                                1
occupation                                        10
zip                                            48067
title         One Flew Over the Cuckoo's Nest (1975)
genres                                         Drama
Name: 0, dtype: object
-------------------
gender                                F         M
title                                            
$1,000,000 Duck (1971)         3.375000  2.761905
'Night Mother (1986)           3.388889  3.352941
'Til There Was You (1997)      2.675676  2.733333
'burbs, The (1989)             2.793478  2.962085
...And Justice for All (1979)  3.828571  3.689024
-------------------
title
$1,000,000 Duck (1971)                37
'Night Mother (1986)                  70
'Til There Was You (1997)             52
'burbs, The (1989)                   303
...And Justice for All (1979)        199
1-900 (1994)                           2
10 Things I Hate About You (1999)    700
101 Dalmatians (1961)                565
101 Dalmatians (1996)                364
12 Angry Men (1957)                  616
dtype: int64
-------------------
Index([''burbs, The (1989)', '10 Things I Hate About You (1999)',
       '101 Dalmatians (1961)', '101 Dalmatians (1996)', '12 Angry Men (1957)',
       '13th Warrior, The (1999)', '2 Days in the Valley (1996)',
       '20,000 Leagues Under the Sea (1954)', '2001: A Space Odyssey (1968)',
       '2010 (1984)',
       ...
       'X-Men (2000)', 'Year of Living Dangerously (1982)',
       'Yellow Submarine (1968)', 'You've Got Mail (1998)',
       'Young Frankenstein (1974)', 'Young Guns (1988)',
       'Young Guns II (1990)', 'Young Sherlock Holmes (1985)',
       'Zero Effect (1998)', 'eXistenZ (1999)'],
      dtype='object', name='title', length=1216)
-------------------
gender                                    F         M
title                                                
'burbs, The (1989)                 2.793478  2.962085
10 Things I Hate About You (1999)  3.646552  3.311966
101 Dalmatians (1961)              3.791444  3.500000
101 Dalmatians (1996)              3.240000  2.911215
12 Angry Men (1957)                4.184397  4.328421
...                                     ...       ...
Young Guns (1988)                  3.371795  3.425620
Young Guns II (1990)               2.934783  2.904025
Young Sherlock Holmes (1985)       3.514706  3.363344
Zero Effect (1998)                 3.864407  3.723140
eXistenZ (1999)                    3.098592  3.289086

[1216 rows x 2 columns]
-------------------
gender                                                     F         M
title                                                                 
Close Shave, A (1995)                               4.644444  4.473795
Wrong Trousers, The (1993)                          4.588235  4.478261
Sunset Blvd. (a.k.a. Sunset Boulevard) (1950)       4.572650  4.464589
Wallace & Gromit: The Best of Aardman Animation...  4.563107  4.385075
Schindler's List (1993)                             4.562602  4.491415
...                                                      ...       ...
Avengers, The (1998)                                1.915254  2.017467
Speed 2: Cruise Control (1997)                      1.906667  1.863014
Rocky V (1990)                                      1.878788  2.132780
Barb Wire (1996)                                    1.585366  2.100386
Battlefield Earth (2000)                            1.574468  1.616949

[1216 rows x 2 columns]
-------------------

Process finished with exit code 0

```



- 평점 차이 구하기

```python
import pandas as pd

# 출력되는 내용 줄이기
pd.options.display.max_rows = 10

unames = ['user_id', 'gender', 'age', 'occupation', 'zip']
users = pd.read_table('C:\\Users\\BIT\\Desktop\\KHY\\7_DataAnalysis\\0806\\pydata-book-2nd-edition\\datasets\\movielens\\users.dat',
                      sep='::', names=unames, engine='python')

rnames = ['user_id', 'movie_id', 'rating', 'timestamp']
ratings = pd.read_table('C:\\Users\\BIT\\Desktop\\KHY\\7_DataAnalysis\\0806\\pydata-book-2nd-edition\\datasets\\movielens\\ratings.dat',
                      sep='::', header=None, names=rnames, engine='python')

mnames = ['movie_id', 'title', 'genres']
movies = pd.read_table('C:\\Users\\BIT\\Desktop\\KHY\\7_DataAnalysis\\0806\\pydata-book-2nd-edition\\datasets\\movielens\\movies.dat',
                      sep='::', header=None, names=mnames, engine='python')


# 모든 데이터를 하나의 테이블로 병합하여 계산
data = pd.merge(pd.merge(ratings, users), movies)  # pandas의 merge()를 이용해 ratings 테이블과 users 테이블을 병합하고 그 결과를 다시 movies 테이블과 병합


# 성별에 따른 각 영화의 평균 평점
mean_ratings = data.pivot_table('rating', index='title',
                                columns='gender', aggfunc='mean')  # pivot_table()메서드 사용


# 250건 이상의 평점 정보가 있는 영화 추리기
ratings_by_title = data.groupby('title').size()  # 영화 제목으로 그룹화 후 size()를 사용하여 제목별 평점 정보 건수를 Series 객체로 얻어냄

active_titles = ratings_by_title.index[ratings_by_title >= 250]



# 250건 이상의 평점 정보가 있는 영화에 대한 색인 사용
mean_ratings = mean_ratings.loc[active_titles]  # mean_ratings에서 항목을 선택하기 위해 사용



# 여성에게 높은 평점을 받은 영화목록을 확인하기 위해 F 컬럼 내림차순 정렬
top_female_ratings = mean_ratings.sort_values(by='F', ascending=False)


# 여성들이 더 선호하는 영화 순으로 출력
mean_ratings['diff'] = mean_ratings['M'] - mean_ratings['F']  # mean_ratings에 diff 컬럼 추가
sorted_by_diff = mean_ratings.sort_values(by='diff')
print(sorted_by_diff[:10])
print('------------------------')


# 남성의 선호도 순으로 출력
print(sorted_by_diff[::-1][:10])  # 뒤에서 10개의 로우 선택


# 호불호가 극명하게 나뉘는 영화 찾기
# 평점의 분산이나 표준편차로 나누기
rating_std_by_title = data.groupby('title')['rating'].std()  # 영화별 평점 표준편차
rating_std_by_title = rating_std_by_title.loc[active_titles]  # active_titles만 선택
print(rating_std_by_title.sort_values(ascending=False)[:10])  # 평점 내림차순으로 Series 정렬
print('------------------------')

```

```
D:\KHY\pycharm_workspace\exam01\venv\Scripts\python.exe D:/KHY/pycharm_workspace/exam01/0806.py
gender                                        F         M      diff
title                                                              
Dirty Dancing (1987)                   3.790378  2.959596 -0.830782
Jumpin' Jack Flash (1986)              3.254717  2.578358 -0.676359
Grease (1978)                          3.975265  3.367041 -0.608224
Little Women (1994)                    3.870588  3.321739 -0.548849
Steel Magnolias (1989)                 3.901734  3.365957 -0.535777
Anastasia (1997)                       3.800000  3.281609 -0.518391
Rocky Horror Picture Show, The (1975)  3.673016  3.160131 -0.512885
Color Purple, The (1985)               4.158192  3.659341 -0.498851
Age of Innocence, The (1993)           3.827068  3.339506 -0.487561
Free Willy (1993)                      2.921348  2.438776 -0.482573
------------------------
gender                                         F         M      diff
title                                                               
Good, The Bad and The Ugly, The (1966)  3.494949  4.221300  0.726351
Kentucky Fried Movie, The (1977)        2.878788  3.555147  0.676359
Dumb & Dumber (1994)                    2.697987  3.336595  0.638608
Longest Day, The (1962)                 3.411765  4.031447  0.619682
Cable Guy, The (1996)                   2.250000  2.863787  0.613787
Evil Dead II (Dead By Dawn) (1987)      3.297297  3.909283  0.611985
Hidden, The (1987)                      3.137931  3.745098  0.607167
Rocky III (1982)                        2.361702  2.943503  0.581801
Caddyshack (1980)                       3.396135  3.969737  0.573602
For a Few Dollars More (1965)           3.409091  3.953795  0.544704
title
Dumb & Dumber (1994)                     1.321333
Blair Witch Project, The (1999)          1.316368
Natural Born Killers (1994)              1.307198
Tank Girl (1995)                         1.277695
Rocky Horror Picture Show, The (1975)    1.260177
Eyes Wide Shut (1999)                    1.259624
Evita (1996)                             1.253631
Billy Madison (1995)                     1.249970
Fear and Loathing in Las Vegas (1998)    1.246408
Bicentennial Man (1999)                  1.245533
Name: rating, dtype: float64

Process finished with exit code 0

```

> 영화 장르가 파이프(|)로 구분하여 제공되고 있는데, 만일 영화 장르에 기반한 분석을 하려면 영화 장르 정보를 좀 더 사용하기 편한 형식으로 변형할 필요가 있음





### 신생아 이름

- DataFrame 객체 불러오기

```python
import pandas as pd

# DataFrame 객체 불러오기
names1880 = pd.read_csv('C:\\Users\\BIT\\Desktop\KHY\\7_DataAnalysis\\0806\\pydata-book-2nd-edition\\datasets\\babynames\\yob1880.txt',
                        names=['name', 'sex', 'births'])
print(names1880)
print('----------------------')

print(names1880.groupby('sex').births.sum())  # 편의상 성별별 출생수를 모두 합한 값을 해당 연도의 전체 출생수라고 가정

```

```
D:\KHY\pycharm_workspace\exam01\venv\Scripts\python.exe D:/KHY/pycharm_workspace/exam01/0806.py
           name sex  births
0          Mary   F    7065
1          Anna   F    2604
2          Emma   F    2003
3     Elizabeth   F    1939
4        Minnie   F    1746
...         ...  ..     ...
1995     Woodie   M       5
1996     Worthy   M       5
1997     Wright   M       5
1998       York   M       5
1999  Zachariah   M       5

[2000 rows x 3 columns]
----------------------
sex
F     90993
M    110493
Name: births, dtype: int64

Process finished with exit code 0

```

> 데이터 생김새



- 모든 데이터를 DataFrame 하나로 모으기

```python
import pandas as pd
import matplotlib.pyplot as plt

years = range(1880, 2011)
pieces = []
columns = ['name', 'sex', 'births']

for year in years:
    path = 'C:\\Users\\BIT\\Desktop\\KHY\\7_DataAnalysis\\0806_\\pydata-book-2nd-edition\\datasets\\babynames\\yob%d.txt' % year
    frame = pd.read_csv(path, names=columns)

    frame['year'] = year
    pieces.append(frame)


# 하나의 DataFrame으로 합치기
names = pd.concat(pieces, ignore_index=True)  # contact(): DataFrame객체를 합쳐줌, read_csv()로 읽어온 원래 로우 순서는 몰라도 되므로 ignore_index=True 설정해야함
print(names)
print('--------------------')


# groupby나 pivot_table을 이용하여 연도나 성별에 따른 데이터 수집
total_births = names.pivot_table('births', index='year',
                                 columns='sex', aggfunc=sum)  # aggregation function
print(total_births.tail())
total_births.plot(title='Total births by sex and year')
plt.show()
print('-----------------')


# prop 컬럼을 추가하여 각 이름이 전체 출생수에서 차지하는 비율 계산
def add_prop(group):
    group['prop'] = group.births / group.births.sum()
    return group

names = names.groupby(['year', 'sex']).apply(add_prop)  # names에 prop 컬럼 추가
print(names)
print('-----------------')


# prop 컬럼의 합이 1이 맞는 지 확인하는 새너티 테스트
print(names.groupby(['year', 'sex']).prop.sum())
print('-----------------')


# 각 연도별/성별에 따른 선호하는 이름 1000개 추출
def get_top1000(group):
    return group.sort_values(by='births', ascending=False)[:1000]

grouped = names.groupby(['year', 'sex'])
top1000 = grouped.apply(get_top1000)
top1000.reset_index(inplace=True, drop=True)  # 그룹 색인은 필요없으므로 삭제
"""
# 함수를 정의하지 않고 직접 추출하는 코드
pieces = []
for year, group in names.groupby(['year', 'sex']):
    pieces.append(group.sort_values(by='births', ascending=False)[:1000]

top1000 = pd.concat(pieces, ignore_index=True)
"""
print(top1000)
```

```
D:\KHY\pycharm_workspace\exam01\venv\Scripts\python.exe D:/KHY/pycharm_workspace/exam01/0806.py
              name sex  births  year
0             Mary   F    7065  1880
1             Anna   F    2604  1880
2             Emma   F    2003  1880
3        Elizabeth   F    1939  1880
4           Minnie   F    1746  1880
...            ...  ..     ...   ...
1690779    Zymaire   M       5  2010
1690780     Zyonne   M       5  2010
1690781  Zyquarius   M       5  2010
1690782      Zyran   M       5  2010
1690783      Zzyzx   M       5  2010

[1690784 rows x 4 columns]
--------------------
sex         F        M
year                  
2006  1896468  2050234
2007  1916888  2069242
2008  1883645  2032310
2009  1827643  1973359
2010  1759010  1898382
-----------------
              name sex  births  year      prop
0             Mary   F    7065  1880  0.077643
1             Anna   F    2604  1880  0.028618
2             Emma   F    2003  1880  0.022013
3        Elizabeth   F    1939  1880  0.021309
4           Minnie   F    1746  1880  0.019188
...            ...  ..     ...   ...       ...
1690779    Zymaire   M       5  2010  0.000003
1690780     Zyonne   M       5  2010  0.000003
1690781  Zyquarius   M       5  2010  0.000003
1690782      Zyran   M       5  2010  0.000003
1690783      Zzyzx   M       5  2010  0.000003

[1690784 rows x 5 columns]
-----------------
year  sex
1880  F      1.0
      M      1.0
1881  F      1.0
      M      1.0
1882  F      1.0
            ... 
2008  M      1.0
2009  F      1.0
      M      1.0
2010  F      1.0
      M      1.0
Name: prop, Length: 262, dtype: float64
-----------------
             name sex  births  year      prop
0            Mary   F    7065  1880  0.077643
1            Anna   F    2604  1880  0.028618
2            Emma   F    2003  1880  0.022013
3       Elizabeth   F    1939  1880  0.021309
4          Minnie   F    1746  1880  0.019188
...           ...  ..     ...   ...       ...
261872     Camilo   M     194  2010  0.000102
261873     Destin   M     194  2010  0.000102
261874     Jaquan   M     194  2010  0.000102
261875     Jaydan   M     194  2010  0.000102
261876     Maxton   M     193  2010  0.000102

[261877 rows x 5 columns]

Process finished with exit code 0

```



- 이름 유행 분석

```python
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

years = range(1880, 2011)
pieces = []
columns = ['name', 'sex', 'births']

for year in years:
    path = 'C:\\Users\\BIT\\Desktop\\KHY\\7_DataAnalysis\\0806_\\pydata-book-2nd-edition\\datasets\\babynames\\yob%d.txt' % year
    frame = pd.read_csv(path, names=columns)
    frame['year'] = year
    pieces.append(frame)


# 하나의 DataFrame으로 합치기
names = pd.concat(pieces, ignore_index=True)


# groupby나 pivot_table을 이용하여 연도나 성별에 따른 데이터 수집
total_births = names.pivot_table('births', index='year',
                                 columns='sex', aggfunc=sum)


# prop 컬럼을 추가하여 각 이름이 전체 출생수에서 차지하는 비율 계산
def add_prop(group):
    group['prop'] = group.births / group.births.sum()
    return group

names = names.groupby(['year', 'sex']).apply(add_prop)


# 각 연도별/성별에 따른 선호하는 이름 1000개 추출
def get_top1000(group):
    return group.sort_values(by='births', ascending=False)[:1000]

grouped = names.groupby(['year', 'sex'])
top1000 = grouped.apply(get_top1000)
top1000.reset_index(inplace=True, drop=True)


# 상위 1000개의 데이터를 남자와 여자로 분리
boys = top1000[top1000.sex == 'M']
girs = top1000[top1000.sex == 'F']
total_births = top1000.pivot_table('births', index='year',
                                   columns='name', aggfunc=sum)  # 연도와 이름에 대한 전체 출생수 피벗테이블(데이터 변경을 위한 사전작업)
total_births.info()
print('-----------------------')
subset = total_births[['John', 'Harry', 'Mary', 'Marilyn']]
subset.plot(subplots=True, figsize=(12, 10), grid=False,
            title="Number of births per year")  # plot()메서드를 사용하여 그래프 그리기
plt.show()


# 다양한 이름을 사용하는 경향 측정하기
table = top1000.pivot_table('prop', index='year',
                            columns='sex', aggfunc=sum)  # 인기있는 이름 1000개가 전체 출생수에 차지하는 비율을 연도별/성별 그래프로 그리기
table.plot(title='Sum of table1000.prop by year and sex',
           yticks=np.linspace(0, 1.2, 13), xticks=range(1880, 2020, 10))
plt.show()

df = boys[boys.year == 2010]
print(df)
print('-----------------------')

prop_cumsum = df.sort_values(by='prop', ascending=False).prop.cumsum()  # prop을 내림차순 정렬하고 전체의 50%가 되기까지 얼마나 많은 이름이 등장하는지 보기
print(prop_cumsum)
print('-----------------------')

print(prop_cumsum.values.searchsorted(0.5))  # prop의 누계를 cumsum에 저장하고 searchsorted()로 정렬된 상태에서 누계가 0.5가 되는 위치를 구함
print('-----------------------')

df = boys[boys.year == 1900]
in1900 = df.sort_values(by='prop', ascending=False).prop.cumsum()
print(in1900.values.searchsorted(0.5) + 1)  # 배열의 색인은 0부터 시작하기 때문에 결과에 1을 더해줌
print('-----------------------')

def get_quantile_count(group, q=0.5):
    group = group.sort_values(by='prop', ascending=False)
    return group.prop.cumsum().values.searchsorted(q) + 1

diversity = top1000.groupby(['year', 'sex']).apply(get_quantile_count)  # 연도와 성을 groupby로 묶고 각 그룹에 apply()
diversity = diversity.unstack('sex')
print(diversity.head())  # diversity DataFrame은 각 성별에 따라 연도별로 색인된 두 개의 시계열 데이터를 담고 있음
print('-----------------------')

diversity.plot(title="Number of popular names in top 50%")
plt.show()  # 여자 이름은 항상 남자 이름보다 더 다양하며 시간이 흐를수록 더욱 다양해지고 있음
```

```
D:\KHY\pycharm_workspace\exam01\venv\Scripts\python.exe D:/KHY/pycharm_workspace/exam01/0806.py
<class 'pandas.core.frame.DataFrame'>
Int64Index: 131 entries, 1880 to 2010
Columns: 6868 entries, Aaden to Zuri
dtypes: float64(6868)
memory usage: 6.9 MB
-----------------------
           name sex  births  year      prop
260877    Jacob   M   21875  2010  0.011523
260878    Ethan   M   17866  2010  0.009411
260879  Michael   M   17133  2010  0.009025
260880   Jayden   M   17030  2010  0.008971
260881  William   M   16870  2010  0.008887
...         ...  ..     ...   ...       ...
261872   Camilo   M     194  2010  0.000102
261873   Destin   M     194  2010  0.000102
261874   Jaquan   M     194  2010  0.000102
261875   Jaydan   M     194  2010  0.000102
261876   Maxton   M     193  2010  0.000102

[1000 rows x 5 columns]
-----------------------
260877    0.011523
260878    0.020934
260879    0.029959
260880    0.038930
260881    0.047817
            ...   
261872    0.842748
261873    0.842850
261874    0.842953
261875    0.843055
261876    0.843156
Name: prop, Length: 1000, dtype: float64
-----------------------
116
-----------------------
25
-----------------------
sex    F   M
year        
1880  38  14
1881  38  14
1882  38  15
1883  39  15
1884  39  16
-----------------------

Process finished with exit code 0

```



- 마지막 글자 변화

```python
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

years = range(1880, 2011)
pieces = []
columns = ['name', 'sex', 'births']

for year in years:
    path = 'C:\\Users\\BIT\\Desktop\\KHY\\7_DataAnalysis\\0806_\\pydata-book-2nd-edition\\datasets\\babynames\\yob%d.txt' % year
    frame = pd.read_csv(path, names=columns)
    frame['year'] = year
    pieces.append(frame)


# 하나의 DataFrame으로 합치기
names = pd.concat(pieces, ignore_index=True)


# groupby나 pivot_table을 이용하여 연도나 성별에 따른 데이터 수집
total_births = names.pivot_table('births', index='year',
                                 columns='sex', aggfunc=sum)


# prop 컬럼을 추가하여 각 이름이 전체 출생수에서 차지하는 비율 계산
def add_prop(group):
    group['prop'] = group.births / group.births.sum()
    return group

names = names.groupby(['year', 'sex']).apply(add_prop)


# 각 연도별/성별에 따른 선호하는 이름 1000개 추출
def get_top1000(group):
    return group.sort_values(by='births', ascending=False)[:1000]

grouped = names.groupby(['year', 'sex'])
top1000 = grouped.apply(get_top1000)
top1000.reset_index(inplace=True, drop=True)


# 상위 1000개의 데이터를 남자와 여자로 분리
boys = top1000[top1000.sex == 'M']
girs = top1000[top1000.sex == 'F']
total_births = top1000.pivot_table('births', index='year',
                                   columns='name', aggfunc=sum)  # 연도와 이름에 대한 전체 출생수 피벗테이블(데이터 변경을 위한 사전작업)
subset = total_births[['John', 'Harry', 'Mary', 'Marilyn']]
subset.plot(subplots=True, figsize=(12, 10), grid=False,
            title="Number of births per year")  # plot()메서드를 사용하여 그래프 그리기


# 다양한 이름을 사용하는 경향 측정하기
table = top1000.pivot_table('prop', index='year',
                            columns='sex', aggfunc=sum)
table.plot(title='Sum of table1000.prop by year and sex',
           yticks=np.linspace(0, 1.2, 13), xticks=range(1880, 2020, 10))

df = boys[boys.year == 2010]

prop_cumsum = df.sort_values(by='prop', ascending=False).prop.cumsum()

df = boys[boys.year == 1900]
in1900 = df.sort_values(by='prop', ascending=False).prop.cumsum()

def get_quantile_count(group, q=0.5):
    group = group.sort_values(by='prop', ascending=False)
    return group.prop.cumsum().values.searchsorted(q) + 1

diversity = top1000.groupby(['year', 'sex']).apply(get_quantile_count)
diversity = diversity.unstack('sex')

diversity.plot(title="Number of popular names in top 50%")


# 마지막 글자 변화
get_last_letter = lambda x: x[-1]  # name 컬럼에서 마지막 글자 추출
last_letters = names.name.map(get_last_letter)  # map(): 리스트의 요소를 지정된 함수로 처리해주는 함수(원본 리스트를 변경하지 않고 새 리스트를 생성)
last_letters.name = 'last_letter'

table = names.pivot_table('births', index=last_letters,
                          columns=['sex', 'year'], aggfunc=sum)

subtable = table.reindex(columns=[1910, 1960, 2010], level='year')  # reindex(): 인덱스 재설정 하기
print(subtable.head())  # 전체 기간 중 세 지점(1910, 1960, 2010)을 골라 마지막 글자 몇 개 출력
print('-----------------------------')
print(subtable.sum())
print('-----------------------------')
letter_prop = subtable / subtable.sum()  # 전체 출생수에서 성별별로 각각의 마지막 글자가 차지하는 비율 계산을 위한 전체 출생수 정규화
print(letter_prop)
print('-----------------------------')

fig, axes = plt.subplots(2, 1, figsize=(10, 8))  # subplot(): 하나의 figure에 여러개의 플롯을 작성
letter_prop['M'].plot(kind='bar', rot=0, ax=axes[0], title='Male')
letter_prop['F'].plot(kind='bar', rot=0, ax=axes[1], title='Female', legend=False)
plt.show()

letter_prop = table / table.sum()
dny_ts = letter_prop.loc[['d', 'n', 'y'], 'M'].T  # 전체 자료에 대해 출생연도와 성별, 남자 이름에서 몇 가지 글자로 정규화하고 시계열 데이터로 변환
print(dny_ts.head())
print('-----------------------------')
dny_ts.plot()
plt.show()


# 남자 이름과 여자 이름이 바뀐 경우
all_names = pd.Series(top1000.name.unique())  # unique(): 유일한 값 찾기
lesley_like = all_names[all_names.str.lower().str.contains('lesl')]  # contains(): 특정 문자열을 포함하는 요소를 찾음
print(lesley_like)  # top1000 데이터를 이용하여 'lesl'로 시작하는 이름을 포함하는 목록 만듦
print('-----------------------------')

filtered = top1000[top1000.name.isin(lesley_like)]  # isin(): 요소가 Series나 DataFrame안에 있는 지 판별 / 이름별로 출생수를 구하고 상대도수 확인
print(filtered.groupby('name').births.sum())  # groupby(): 데이터 그룹화, split-apply-combine 순서
print('-----------------------------')

table = filtered.pivot_table('births', index='year', columns='sex', aggfunc='sum')  # pivot_table(): 테이블에 요약된 정보 출력
table = table.div(table.sum(1), axis=0)  # axis 파라미터: 다차원 배열의 축(0은 1차원, 1은 2차원)
print(table.tail())  # 성별과 연도별로 모은 다음 출생연도로 정규화

table.plot(style={'M': 'k-', 'F': 'k--'})  # 시대별로 성별에 따른 명세를 그래프로 그림
plt.show()
```

```
D:\KHY\pycharm_workspace\exam01\venv\Scripts\python.exe D:/KHY/pycharm_workspace/exam01/0806.py
sex                 F                            M                    
year             1910      1960      2010     1910      1960      2010
last_letter                                                           
a            108376.0  691247.0  670605.0    977.0    5204.0   28438.0
b                 NaN     694.0     450.0    411.0    3912.0   38859.0
c                 5.0      49.0     946.0    482.0   15476.0   23125.0
d              6750.0    3729.0    2607.0  22111.0  262112.0   44398.0
e            133569.0  435013.0  313833.0  28655.0  178823.0  129012.0
-----------------------------
sex  year
F    1910     396416.0
     1960    2022062.0
     2010    1759010.0
M    1910     194198.0
     1960    2132588.0
     2010    1898382.0
dtype: float64
-----------------------------
sex                 F                             M                    
year             1910      1960      2010      1910      1960      2010
last_letter                                                            
a            0.273390  0.341853  0.381240  0.005031  0.002440  0.014980
b                 NaN  0.000343  0.000256  0.002116  0.001834  0.020470
c            0.000013  0.000024  0.000538  0.002482  0.007257  0.012181
d            0.017028  0.001844  0.001482  0.113858  0.122908  0.023387
e            0.336941  0.215133  0.178415  0.147556  0.083853  0.067959
f                 NaN  0.000010  0.000055  0.000783  0.004325  0.001188
g            0.000144  0.000157  0.000374  0.002250  0.009488  0.001404
h            0.051529  0.036224  0.075852  0.045562  0.037907  0.051670
i            0.001526  0.039965  0.031734  0.000844  0.000603  0.022628
j                 NaN       NaN  0.000090       NaN       NaN  0.000769
k            0.000121  0.000156  0.000356  0.036581  0.049384  0.018541
l            0.043189  0.033867  0.026356  0.065016  0.104904  0.070367
m            0.001201  0.008613  0.002588  0.058044  0.033827  0.024657
n            0.079240  0.130687  0.140210  0.143415  0.152522  0.362771
o            0.001660  0.002439  0.001243  0.017065  0.012829  0.042681
p            0.000018  0.000023  0.000020  0.003172  0.005675  0.001269
q                 NaN       NaN  0.000030       NaN       NaN  0.000180
r            0.013390  0.006764  0.018025  0.064481  0.031034  0.087477
s            0.039042  0.012764  0.013332  0.130815  0.102730  0.065145
t            0.027438  0.015201  0.007830  0.072879  0.065655  0.022861
u            0.000684  0.000574  0.000417  0.000124  0.000057  0.001221
v                 NaN  0.000060  0.000117  0.000113  0.000037  0.001434
w            0.000020  0.000031  0.001182  0.006329  0.007711  0.016148
x            0.000015  0.000037  0.000727  0.003965  0.001851  0.008614
y            0.110972  0.152569  0.116828  0.077349  0.160987  0.058168
z            0.002439  0.000659  0.000704  0.000170  0.000184  0.001831
-----------------------------
last_letter         d         n         y
year                                     
1880         0.083055  0.153213  0.075760
1881         0.083247  0.153214  0.077451
1882         0.085340  0.149560  0.077537
1883         0.084066  0.151646  0.079144
1884         0.086120  0.149915  0.080405
-----------------------------
632     Leslie
2294    Lesley
4262    Leslee
4728     Lesli
6103     Lesly
dtype: object
-----------------------------
name
Leslee      1082
Lesley     35022
Lesli        929
Leslie    370429
Lesly      10067
Name: births, dtype: int64
-----------------------------
sex     F   M
year         
2006  1.0 NaN
2007  1.0 NaN
2008  1.0 NaN
2009  1.0 NaN
2010  1.0 NaN

Process finished with exit code 0

```





### 미국 농무부 영양소 정보

```python
import json
import pandas as pd
import matplotlib.pyplot as plt

db = json.load(open('C:\\Users\\BIT\\Desktop\\KHY\\7_DataAnalysis\\0806_0807\\pydata-book-2nd-edition\\datasets\\usda_food\\database.json'))


# 데이터 다듬기
print(len(db))
print('-------------------')

print(db[0].keys())  # db에 있는 각 엔트리는 한 가지 음식에 대한 모든 정보를 담고있는 사전형
print('-------------------')
print(db[0]['nutrients'][0])  # nutrients 필드는 사전 리스트이며 각 항목은 한 가지 영양소에 대한 정보 담고 있음
print('-------------------')
nutrients = pd.DataFrame(db[0]['nutrients'])
nutrients = nutrients[['description', 'group', 'units', 'value']]
print(nutrients[:7])
print('-------------------')

info_keys = ['description', 'group', 'id', 'manufacturer']  # 사전의 리스트를 DataFrame으로 바꿀 때 추출할 필드 목록을 지정해 줄 수 있음
info = pd.DataFrame(db, columns=info_keys)  # 음식의 이름, 그룹, id, 제조사 추출
print(info[:5])
print('-------------------')
info.info()
print('-------------------')

print(pd.value_counts(info.group)[:10])  # value_counts()메서드로 음식 그룹의 분포 확인
print('-------------------')

nutrients = []  # 음식의 영양소 리스트를 하나의 DataFrame으로 변환하고 음식의 id를 위한 컬럼 하나 추가, 이 DataFrame을 리스트에 추가
for rec in db:
    fnuts = pd.DataFrame(rec['nutrients'])
    fnuts['id'] = rec['id']
    nutrients.append(fnuts)

nutrients = pd.concat(nutrients, ignore_index=True)  # concat() 메서드로 하나로 합침
nutrients = nutrients[['description', 'group', 'units', 'value', 'id']]
print(nutrients)  # 모든 영양소 정보 분석
print('-------------------')

print(nutrients.duplicated().sum())  # duplicated(): 중복확인
print('-------------------')
nutrients = nutrients.drop_duplicates()  # drop_duplicates(): 중복된 데이터 제거

col_mappping = {'description': 'food',
                'group': 'fgroup'}  # 알아보기 쉽도록 이름 바꾸기
info = info.rename(columns=col_mappping, copy=False)
info.info()
print('-------------------')

col_mappping = {'description': 'nutrient',
                'group': 'nutgroup'}  # 알아보기 쉽도록 이름 바꾸기
nutrients = nutrients.rename(columns=col_mappping, copy=False)
print(nutrients)
print('-------------------')

ndata = pd.merge(nutrients, info, on='id', how='outer')  # info 객체를 nutrients 객체로 병합
ndata.info()
print('-------------------')
print(ndata.iloc[3000])
print('-------------------')

result = ndata.groupby(['nutrient', 'fgroup'])['value'].quantile(0.5)  # 음식 그룹과 영양소 종류별 중간값을 그래프로 만들기
result['Zinc, Zn'].sort_values().plot(kind='barh')
plt.show()

by_nutrient = ndata.groupby(['nutgroup', 'nutrient'])  # 각 영양소가 어떤 음식에 가장 많이 들어 있는지 찾기
get_maximum = lambda x: x.loc[x.value.idxmax()]
get_minimum = lambda x: x.loc[x.value.dixmin()]
max_foods = by_nutrient.apply(get_maximum)[['value', 'food']]
max_foods.food = max_foods.food.str[:50]  # 음식 종류 제한
print(max_foods.loc['Amino Acids']['food'])  # DataFrame 중 아미노산 내용
```

```
D:\KHY\pycharm_workspace\exam01\venv\Scripts\python.exe D:/KHY/pycharm_workspace/exam01/0806.py
6636
-------------------
dict_keys(['id', 'description', 'tags', 'manufacturer', 'group', 'portions', 'nutrients'])
-------------------
{'value': 25.18, 'units': 'g', 'description': 'Protein', 'group': 'Composition'}
-------------------
                   description        group units    value
0                      Protein  Composition     g    25.18
1            Total lipid (fat)  Composition     g    29.20
2  Carbohydrate, by difference  Composition     g     3.06
3                          Ash        Other     g     3.28
4                       Energy       Energy  kcal   376.00
5                        Water  Composition     g    39.28
6                       Energy       Energy    kJ  1573.00
-------------------
                          description  ... manufacturer
0                     Cheese, caraway  ...             
1                     Cheese, cheddar  ...             
2                        Cheese, edam  ...             
3                        Cheese, feta  ...             
4  Cheese, mozzarella, part skim milk  ...             

[5 rows x 4 columns]
-------------------
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 6636 entries, 0 to 6635
Data columns (total 4 columns):
 #   Column        Non-Null Count  Dtype 
---  ------        --------------  ----- 
 0   description   6636 non-null   object
 1   group         6636 non-null   object
 2   id            6636 non-null   int64 
 3   manufacturer  5195 non-null   object
dtypes: int64(1), object(3)
memory usage: 207.5+ KB
-------------------
Vegetables and Vegetable Products    812
Beef Products                        618
Baked Products                       496
Breakfast Cereals                    403
Fast Foods                           365
Legumes and Legume Products          365
Lamb, Veal, and Game Products        345
Sweets                               341
Fruits and Fruit Juices              328
Pork Products                        328
Name: group, dtype: int64
-------------------
                               description        group units    value     id
0                                  Protein  Composition     g   25.180   1008
1                        Total lipid (fat)  Composition     g   29.200   1008
2              Carbohydrate, by difference  Composition     g    3.060   1008
3                                      Ash        Other     g    3.280   1008
4                                   Energy       Energy  kcal  376.000   1008
...                                    ...          ...   ...      ...    ...
389350                 Vitamin B-12, added     Vitamins   mcg    0.000  43546
389351                         Cholesterol        Other    mg    0.000  43546
389352        Fatty acids, total saturated        Other     g    0.072  43546
389353  Fatty acids, total monounsaturated        Other     g    0.028  43546
389354  Fatty acids, total polyunsaturated        Other     g    0.041  43546

[389355 rows x 5 columns]
-------------------
14179
-------------------
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 6636 entries, 0 to 6635
Data columns (total 4 columns):
 #   Column        Non-Null Count  Dtype 
---  ------        --------------  ----- 
 0   food          6636 non-null   object
 1   fgroup        6636 non-null   object
 2   id            6636 non-null   int64 
 3   manufacturer  5195 non-null   object
dtypes: int64(1), object(3)
memory usage: 207.5+ KB
-------------------
                                  nutrient     nutgroup units    value     id
0                                  Protein  Composition     g   25.180   1008
1                        Total lipid (fat)  Composition     g   29.200   1008
2              Carbohydrate, by difference  Composition     g    3.060   1008
3                                      Ash        Other     g    3.280   1008
4                                   Energy       Energy  kcal  376.000   1008
...                                    ...          ...   ...      ...    ...
389350                 Vitamin B-12, added     Vitamins   mcg    0.000  43546
389351                         Cholesterol        Other    mg    0.000  43546
389352        Fatty acids, total saturated        Other     g    0.072  43546
389353  Fatty acids, total monounsaturated        Other     g    0.028  43546
389354  Fatty acids, total polyunsaturated        Other     g    0.041  43546

[375176 rows x 5 columns]
-------------------
<class 'pandas.core.frame.DataFrame'>
Int64Index: 375176 entries, 0 to 375175
Data columns (total 8 columns):
 #   Column        Non-Null Count   Dtype  
---  ------        --------------   -----  
 0   nutrient      375176 non-null  object 
 1   nutgroup      375176 non-null  object 
 2   units         375176 non-null  object 
 3   value         375176 non-null  float64
 4   id            375176 non-null  int64  
 5   food          375176 non-null  object 
 6   fgroup        375176 non-null  object 
 7   manufacturer  293054 non-null  object 
dtypes: float64(1), int64(1), object(6)
memory usage: 25.8+ MB
-------------------
nutrient                 Alcohol, ethyl
nutgroup                          Other
units                                 g
value                                 0
id                                 1159
food            Cheese, goat, soft type
fgroup           Dairy and Egg Products
manufacturer                           
Name: 3000, dtype: object
-------------------
nutrient
Alanine                           Gelatins, dry powder, unsweetened
Arginine                               Seeds, sesame flour, low-fat
Aspartic acid                                   Soy protein isolate
Cystine                Seeds, cottonseed flour, low fat (glandless)
Glutamic acid                                   Soy protein isolate
Glycine                           Gelatins, dry powder, unsweetened
Histidine                Whale, beluga, meat, dried (Alaska Native)
Hydroxyproline    KENTUCKY FRIED CHICKEN, Fried Chicken, ORIGINA...
Isoleucine        Soy protein isolate, PROTEIN TECHNOLOGIES INTE...
Leucine           Soy protein isolate, PROTEIN TECHNOLOGIES INTE...
Lysine            Seal, bearded (Oogruk), meat, dried (Alaska Na...
Methionine                    Fish, cod, Atlantic, dried and salted
Phenylalanine     Soy protein isolate, PROTEIN TECHNOLOGIES INTE...
Proline                           Gelatins, dry powder, unsweetened
Serine            Soy protein isolate, PROTEIN TECHNOLOGIES INTE...
Threonine         Soy protein isolate, PROTEIN TECHNOLOGIES INTE...
Tryptophan         Sea lion, Steller, meat with fat (Alaska Native)
Tyrosine          Soy protein isolate, PROTEIN TECHNOLOGIES INTE...
Valine            Soy protein isolate, PROTEIN TECHNOLOGIES INTE...
Name: food, dtype: object

Process finished with exit code 0

```





### 2012년 연방선거관리위원회 데이터베이스

```python
import pandas as pd

fec = pd.read_csv('C:\\Users\\BIT\\Desktop\\KHY\\7_DataAnalysis\\0806_\\pydata-book-2nd-edition\\datasets\\fec\\P00000001-ALL.csv', encoding='utf-8', low_memory=False)
fec.info()
print('-------------------')

print(fec.iloc[123456], ', ', 'Length: ', len(fec.iloc[123456]))  # DataFrame 형태
```

```
D:\KHY\pycharm_workspace\exam01\venv\Scripts\python.exe D:/KHY/pycharm_workspace/exam01/0806.py
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 1001731 entries, 0 to 1001730
Data columns (total 16 columns):
 #   Column             Non-Null Count    Dtype  
---  ------             --------------    -----  
 0   cmte_id            1001731 non-null  object 
 1   cand_id            1001731 non-null  object 
 2   cand_nm            1001731 non-null  object 
 3   contbr_nm          1001731 non-null  object 
 4   contbr_city        1001712 non-null  object 
 5   contbr_st          1001727 non-null  object 
 6   contbr_zip         1001620 non-null  object 
 7   contbr_employer    988002 non-null   object 
 8   contbr_occupation  993301 non-null   object 
 9   contb_receipt_amt  1001731 non-null  float64
 10  contb_receipt_dt   1001731 non-null  object 
 11  receipt_desc       14166 non-null    object 
 12  memo_cd            92482 non-null    object 
 13  memo_text          97770 non-null    object 
 14  form_tp            1001731 non-null  object 
 15  file_num           1001731 non-null  int64  
dtypes: float64(1), int64(1), object(14)
memory usage: 122.3+ MB
-------------------
cmte_id                             C00431445
cand_id                             P80003338
cand_nm                         Obama, Barack
contbr_nm                         ELLMAN, IRA
contbr_city                             TEMPE
contbr_st                                  AZ
contbr_zip                          852816719
contbr_employer      ARIZONA STATE UNIVERSITY
contbr_occupation                   PROFESSOR
contb_receipt_amt                          50
contb_receipt_dt                    01-DEC-11
receipt_desc                              NaN
memo_cd                                   NaN
memo_text                                 NaN
form_tp                                 SA17A
file_num                               772372
Name: 123456, dtype: object ,  Length:  16

Process finished with exit code 0

```

> 데이터 형태



- 데이터 다듬기

```python
import pandas as pd

fec = pd.read_csv('C:\\Users\\BIT\\Desktop\\KHY\\7_DataAnalysis\\0806_\\pydata-book-2nd-edition\\datasets\\fec\\P00000001-ALL.csv', encoding='utf-8', low_memory=False)


unique_cands = fec.cand_nm.unique()  # unique()로 모든 정당의 후보 목록 얻기
print(unique_cands)
print('-----------------')
print(unique_cands[2])
print('-----------------')

parties = {'Bachmann, Michelle': 'Republican',
           'Romney, Mitt': 'Republican',
           'Obama, Barack': 'Democrat',
           "Roemer, Charles E. 'Buddy' III": 'Republican',
           'Pawlenty, Timothy': 'Republican',
           'Johnson, Gary Earl': 'Republican',
           'Paul, Ron': 'Republican',
           'Santorum, Rick': 'Republican',
           'Cain, Herman': 'Republican',
           'Gingrich, Newt': 'Republican',
           'McCotter, Thaddeus G': 'Republican',
           'Huntsman, Jon': 'Republican',
           'Perry, Rick': 'Republican'}  # 소속 정당을 dict를 사용하여 표시

print(fec.cand_nm[123456:123461])  # Series 객체의 map 메서드를 통해 후보이름으로부터 정당 배열 계산 가능
print('-----------------')
print(fec.cand_nm[123456:123461].map(parties))
print('-----------------')

fec['party'] = fec.cand_nm.map(parties)  # party 컬럼으로 추가
print(fec['party'].value_counts())
print('-----------------')

print((fec.contb_receipt_amt > 0).value_counts())  # 데이터 다듬기
print('-----------------')
fec = fec[fec.contb_receipt_amt > 0]  # 단순화를 위해 기부금액이 양수인 데이터만 골라내기
fec_mrbo = fec[fec.cand_nm.isin(['Obama, Barack', 'Romney, Mitt'])]  # 오바마와 롬니가 양대 후보이므로 두 후보의 기부 금액 정보만 추려냄
```

```
D:\KHY\pycharm_workspace\exam01\venv\Scripts\python.exe D:/KHY/pycharm_workspace/exam01/0806.py
['Bachmann, Michelle' 'Romney, Mitt' 'Obama, Barack'
 "Roemer, Charles E. 'Buddy' III" 'Pawlenty, Timothy' 'Johnson, Gary Earl'
 'Paul, Ron' 'Santorum, Rick' 'Cain, Herman' 'Gingrich, Newt'
 'McCotter, Thaddeus G' 'Huntsman, Jon' 'Perry, Rick']
-----------------
Obama, Barack
-----------------
123456    Obama, Barack
123457    Obama, Barack
123458    Obama, Barack
123459    Obama, Barack
123460    Obama, Barack
Name: cand_nm, dtype: object
-----------------
123456    Democrat
123457    Democrat
123458    Democrat
123459    Democrat
123460    Democrat
Name: cand_nm, dtype: object
-----------------
Democrat      593746
Republican    407985
Name: party, dtype: int64
-----------------
True     991475
False     10256
Name: contb_receipt_amt, dtype: int64
-----------------

Process finished with exit code 0

```



- 직업 및 고용주에 따른 기부 통계

```python
import pandas as pd
import matplotlib.pyplot as plt

fec = pd.read_csv('C:\\Users\\BIT\\Desktop\\KHY\\7_DataAnalysis\\0806_\\pydata-book-2nd-edition\\datasets\\fec\\P00000001-ALL.csv', encoding='utf-8', low_memory=False)



# 데이터 다듬기
unique_cands = fec.cand_nm.unique()

parties = {'Bachmann, Michelle': 'Republican',
           'Romney, Mitt': 'Republican',
           'Obama, Barack': 'Democrat',
           "Roemer, Charles E. 'Buddy' III": 'Republican',
           'Pawlenty, Timothy': 'Republican',
           'Johnson, Gary Earl': 'Republican',
           'Paul, Ron': 'Republican',
           'Santorum, Rick': 'Republican',
           'Cain, Herman': 'Republican',
           'Gingrich, Newt': 'Republican',
           'McCotter, Thaddeus G': 'Republican',
           'Huntsman, Jon': 'Republican',
           'Perry, Rick': 'Republican'}

fec['party'] = fec.cand_nm.map(parties)

fec = fec[fec.contb_receipt_amt > 0]
fec_mrbo = fec[fec.cand_nm.isin(['Obama, Barack', 'Romney, Mitt'])]



# 직업 및 고용주에 따른 기부 통계
print(fec.contbr_occupation.value_counts()[:10])  # 직업별 전체 기부 숫자
print('---------------------')

occ_mapping = {
    'INFORMATION REQUESTED PER BEST EFFORTS' : 'NOT PROVIDED',
    'INFORMATION REQUESTED' : 'NOT PROVIDED',
    'INFORMATION REQUESTED (BEST EFFORTS)': 'NOT PROVIDED',
    'C.E.O': 'CEO'
}  # 하나의 직업을 다른 직업으로 매핑(같은 유형이지만 다른 이름으로 많은 결과가 포함되어 있으므로)
f = lambda x: occ_mapping.get(x, x)  # mapping이 없다면 x 반환
fec.contbr_occupation = fec.contbr_occupation.map(f)

emp_mapping = {
    'INFORMATION REQUESTED PER BEST EFFORTS' : 'NOT PROVIDED',
    'INFORMATION REQUESTED' : 'NOT PROVIDED',
    'SELF': 'SELF-EMPLOYED',
    'SELF EMPLOYED': 'SELF-EMPLOYED',
}  # 고용주에 대해서도 마찬가지로 매핑
f = lambda x: emp_mapping.get(x, x)  # mapping이 없다면 x 반환
fec.contbr_employer = fec.contbr_employer.map(f)

by_occupation = fec.pivot_table('contb_receipt_amt',
                                index='contbr_occupation',
                                columns='party', aggfunc='sum')  # 피벗 테이블을 사용하여 정당과 직업별로 데이터를 집계
over_2mm = by_occupation[by_occupation.sum(1) > 2000000]  # 최소 2백만불 이상 기부한 직업 골라내기
print(over_2mm)
print('----------------------')

over_2mm.plot(kind='barh')  # 수평 막대 그래프로 시각화
plt.show()

def get_top_amounts(group, key, n=5):  # 오바마와 롬니 후보별 가장 많은 금액 기부한 직군 알아내는 메서드
    totals = group.groupby(key)['contb_receipt_amt'].sum()
    return totals.nlargest(n)

grouped = fec_mrbo.groupby('cand_nm')  # 직업과 고용주에 따라 집계
print(grouped.apply(get_top_amounts, 'contbr_occupation', n=7))
print(grouped.apply(get_top_amounts, 'contbr_employer', n=10))
```

```
D:\KHY\pycharm_workspace\exam01\venv\Scripts\python.exe D:/KHY/pycharm_workspace/exam01/0806.py
RETIRED                                   233990
INFORMATION REQUESTED                      35107
ATTORNEY                                   34286
HOMEMAKER                                  29931
PHYSICIAN                                  23432
INFORMATION REQUESTED PER BEST EFFORTS     21138
ENGINEER                                   14334
TEACHER                                    13990
CONSULTANT                                 13273
PROFESSOR                                  12555
Name: contbr_occupation, dtype: int64
---------------------
party                 Democrat    Republican
contbr_occupation                           
ATTORNEY           11141982.97  7.477194e+06
C.E.O.                 1690.00  2.592983e+06
CEO                 2074284.79  1.640758e+06
CONSULTANT          2459912.71  2.544725e+06
ENGINEER             951525.55  1.818374e+06
EXECUTIVE           1355161.05  4.138850e+06
HOMEMAKER           4248875.80  1.363428e+07
INVESTOR             884133.00  2.431769e+06
LAWYER              3160478.87  3.912243e+05
MANAGER              762883.22  1.444532e+06
NOT PROVIDED        4866973.96  2.056547e+07
OWNER               1001567.36  2.408287e+06
PHYSICIAN           3735124.94  3.594320e+06
PRESIDENT           1878509.95  4.720924e+06
PROFESSOR           2165071.08  2.967027e+05
REAL ESTATE          528902.09  1.625902e+06
RETIRED            25305116.38  2.356124e+07
SELF-EMPLOYED        672393.40  1.640253e+06
----------------------
cand_nm        contbr_occupation                     
Obama, Barack  RETIRED                                   25305116.38
               ATTORNEY                                  11141982.97
               INFORMATION REQUESTED                      4866973.96
               HOMEMAKER                                  4248875.80
               PHYSICIAN                                  3735124.94
               LAWYER                                     3160478.87
               CONSULTANT                                 2459912.71
Romney, Mitt   RETIRED                                   11508473.59
               INFORMATION REQUESTED PER BEST EFFORTS    11396894.84
               HOMEMAKER                                  8147446.22
               ATTORNEY                                   5364718.82
               PRESIDENT                                  2491244.89
               EXECUTIVE                                  2300947.03
               C.E.O.                                     1968386.11
Name: contb_receipt_amt, dtype: float64
cand_nm        contbr_employer                       
Obama, Barack  RETIRED                                   22694358.85
               SELF-EMPLOYED                             17080985.96
               NOT EMPLOYED                               8586308.70
               INFORMATION REQUESTED                      5053480.37
               HOMEMAKER                                  2605408.54
               SELF                                       1076531.20
               SELF EMPLOYED                               469290.00
               STUDENT                                     318831.45
               VOLUNTEER                                   257104.00
               MICROSOFT                                   215585.36
Romney, Mitt   INFORMATION REQUESTED PER BEST EFFORTS    12059527.24
               RETIRED                                   11506225.71
               HOMEMAKER                                  8147196.22
               SELF-EMPLOYED                              7409860.98
               STUDENT                                     496490.94
               CREDIT SUISSE                               281150.00
               MORGAN STANLEY                              267266.00
               GOLDMAN SACH & CO.                          238250.00
               BARCLAYS CAPITAL                            162750.00
               H.I.G. CAPITAL                              139500.00
Name: contb_receipt_amt, dtype: float64

Process finished with exit code 0

```



- 기부금액

```python
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

fec = pd.read_csv('C:\\Users\\BIT\\Desktop\\KHY\\7_DataAnalysis\\0806_\\pydata-book-2nd-edition\\datasets\\fec\\P00000001-ALL.csv', encoding='utf-8', low_memory=False)



# 데이터 다듬기
unique_cands = fec.cand_nm.unique()

parties = {'Bachmann, Michelle': 'Republican',
           'Romney, Mitt': 'Republican',
           'Obama, Barack': 'Democrat',
           "Roemer, Charles E. 'Buddy' III": 'Republican',
           'Pawlenty, Timothy': 'Republican',
           'Johnson, Gary Earl': 'Republican',
           'Paul, Ron': 'Republican',
           'Santorum, Rick': 'Republican',
           'Cain, Herman': 'Republican',
           'Gingrich, Newt': 'Republican',
           'McCotter, Thaddeus G': 'Republican',
           'Huntsman, Jon': 'Republican',
           'Perry, Rick': 'Republican'}

fec['party'] = fec.cand_nm.map(parties)

fec = fec[fec.contb_receipt_amt > 0]
fec_mrbo = fec[fec.cand_nm.isin(['Obama, Barack', 'Romney, Mitt'])]



# 직업 및 고용주에 따른 기부 통계
occ_mapping = {
    'INFORMATION REQUESTED PER BEST EFFORTS' : 'NOT PROVIDED',
    'INFORMATION REQUESTED' : 'NOT PROVIDED',
    'INFORMATION REQUESTED (BEST EFFORTS)': 'NOT PROVIDED',
    'C.E.O': 'CEO'
}
f = lambda x: occ_mapping.get(x, x)
fec.contbr_occupation = fec.contbr_occupation.map(f)

emp_mapping = {
    'INFORMATION REQUESTED PER BEST EFFORTS' : 'NOT PROVIDED',
    'INFORMATION REQUESTED' : 'NOT PROVIDED',
    'SELF': 'SELF-EMPLOYED',
    'SELF EMPLOYED': 'SELF-EMPLOYED',
}
f = lambda x: emp_mapping.get(x, x)
fec.contbr_employer = fec.contbr_employer.map(f)

by_occupation = fec.pivot_table('contb_receipt_amt',
                                index='contbr_occupation',
                                columns='party', aggfunc='sum')
over_2mm = by_occupation[by_occupation.sum(1) > 2000000]

def get_top_amounts(group, key, n=5):
    totals = group.groupby(key)['contb_receipt_amt'].sum()
    return totals.nlargest(n)

grouped = fec_mrbo.groupby('cand_nm')
grouped.apply(get_top_amounts, 'contbr_occupation', n=7)
grouped.apply(get_top_amounts, 'contbr_employer', n=10)



# 기부금액
bins = np.array([0, 1, 10, 100, 1000, 10000, 100000, 1000000, 10000000])
labels = pd.cut(fec_mrbo.contb_receipt_amt, bins)  # cut()함수로 기부 규모별 버킷을 만들어 기부자 수 분할
print(labels)
print('----------------------')

grouped = fec_mrbo.groupby(['cand_nm', labels])  # 데이터를 이름과 버킷 이름으로 그룹지어 기부금액에 따른 히스토그램 그리기
print(grouped.size().unstack(0))
print('----------------------')

bucket_sums = grouped.contb_receipt_amt.sum().unstack(0)  # 기부금액을 모두 더한 후 버킷별로 정규화해서 후보별 전체 기부금액 대비 비율 시각화
normed_sums = bucket_sums.div(bucket_sums.sum(axis=1), axis=0)
print(normed_sums)
print('----------------------')
normed_sums[:-2].plot(kind='barh')
plt.show()
```

```
D:\KHY\pycharm_workspace\exam01\venv\Scripts\python.exe D:/KHY/pycharm_workspace/exam01/0806.py
411         (10, 100]
412       (100, 1000]
413       (100, 1000]
414         (10, 100]
415         (10, 100]
             ...     
701381      (10, 100]
701382    (100, 1000]
701383        (1, 10]
701384      (10, 100]
701385    (100, 1000]
Name: contb_receipt_amt, Length: 694282, dtype: category
Categories (8, interval[int64]): [(0, 1] < (1, 10] < (10, 100] < (100, 1000] < (1000, 10000] <
                                  (10000, 100000] < (100000, 1000000] < (1000000, 10000000]]
----------------------
cand_nm              Obama, Barack  Romney, Mitt
contb_receipt_amt                               
(0, 1]                         493            77
(1, 10]                      40070          3681
(10, 100]                   372280         31853
(100, 1000]                 153991         43357
(1000, 10000]                22284         26186
(10000, 100000]                  2             1
(100000, 1000000]                3             0
(1000000, 10000000]              4             0
----------------------
cand_nm              Obama, Barack  Romney, Mitt
contb_receipt_amt                               
(0, 1]                    0.805182      0.194818
(1, 10]                   0.918767      0.081233
(10, 100]                 0.910769      0.089231
(100, 1000]               0.710176      0.289824
(1000, 10000]             0.447326      0.552674
(10000, 100000]           0.823120      0.176880
(100000, 1000000]         1.000000           NaN
(1000000, 10000000]       1.000000           NaN
----------------------

Process finished with exit code 0

```



- 주별 기부 통계

```python
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

fec = pd.read_csv('C:\\Users\\BIT\\Desktop\\KHY\\7_DataAnalysis\\0806_\\pydata-book-2nd-edition\\datasets\\fec\\P00000001-ALL.csv', encoding='utf-8', low_memory=False)



# 데이터 다듬기
unique_cands = fec.cand_nm.unique()

parties = {'Bachmann, Michelle': 'Republican',
           'Romney, Mitt': 'Republican',
           'Obama, Barack': 'Democrat',
           "Roemer, Charles E. 'Buddy' III": 'Republican',
           'Pawlenty, Timothy': 'Republican',
           'Johnson, Gary Earl': 'Republican',
           'Paul, Ron': 'Republican',
           'Santorum, Rick': 'Republican',
           'Cain, Herman': 'Republican',
           'Gingrich, Newt': 'Republican',
           'McCotter, Thaddeus G': 'Republican',
           'Huntsman, Jon': 'Republican',
           'Perry, Rick': 'Republican'}

fec['party'] = fec.cand_nm.map(parties)

fec = fec[fec.contb_receipt_amt > 0]
fec_mrbo = fec[fec.cand_nm.isin(['Obama, Barack', 'Romney, Mitt'])]



# 직업 및 고용주에 따른 기부 통계
occ_mapping = {
    'INFORMATION REQUESTED PER BEST EFFORTS' : 'NOT PROVIDED',
    'INFORMATION REQUESTED' : 'NOT PROVIDED',
    'INFORMATION REQUESTED (BEST EFFORTS)': 'NOT PROVIDED',
    'C.E.O': 'CEO'
}
f = lambda x: occ_mapping.get(x, x)
fec.contbr_occupation = fec.contbr_occupation.map(f)

emp_mapping = {
    'INFORMATION REQUESTED PER BEST EFFORTS' : 'NOT PROVIDED',
    'INFORMATION REQUESTED' : 'NOT PROVIDED',
    'SELF': 'SELF-EMPLOYED',
    'SELF EMPLOYED': 'SELF-EMPLOYED',
}
f = lambda x: emp_mapping.get(x, x)
fec.contbr_employer = fec.contbr_employer.map(f)

by_occupation = fec.pivot_table('contb_receipt_amt',
                                index='contbr_occupation',
                                columns='party', aggfunc='sum')
over_2mm = by_occupation[by_occupation.sum(1) > 2000000]

def get_top_amounts(group, key, n=5):
    totals = group.groupby(key)['contb_receipt_amt'].sum()
    return totals.nlargest(n)

grouped = fec_mrbo.groupby('cand_nm')
grouped.apply(get_top_amounts, 'contbr_occupation', n=7)
grouped.apply(get_top_amounts, 'contbr_employer', n=10)



# 기부금액
bins = np.array([0, 1, 10, 100, 1000, 10000, 100000, 1000000, 10000000])
labels = pd.cut(fec_mrbo.contb_receipt_amt, bins)

grouped = fec_mrbo.groupby(['cand_nm', labels])

bucket_sums = grouped.contb_receipt_amt.sum().unstack(0)
normed_sums = bucket_sums.div(bucket_sums.sum(axis=1), axis=0)



# 주별 기부 통계
grouped = fec_mrbo.groupby(['cand_nm', 'contbr_st'])  # 데이터를 후보자와 주별로 집계
totals = grouped.contb_receipt_amt.sum().unstack(0).fillna(0)  # unstack(): 인덱스의 최하위 계층을 컬럼의 최하위 계층으로 올림
totals = totals[totals.sum(1) > 100000]
print(totals[:10])
print('---------------------')

percent = totals.div(totals.sum(1), axis=0)  # 각 로우를 전체 기부금액으로 나누면 각 후보에 대한 주별 전체 기부금액의 상대적 비율을 얻음
print(percent[:10])
```

```
D:\KHY\pycharm_workspace\exam01\venv\Scripts\python.exe D:/KHY/pycharm_workspace/exam01/0806.py
cand_nm    Obama, Barack  Romney, Mitt
contbr_st                             
AK             281840.15      86204.24
AL             543123.48     527303.51
AR             359247.28     105556.00
AZ            1506476.98    1888436.23
CA           23824984.24   11237636.60
CO            2132429.49    1506714.12
CT            2068291.26    3499475.45
DC            4373538.80    1025137.50
DE             336669.14      82712.00
FL            7318178.58    8338458.81
---------------------
cand_nm    Obama, Barack  Romney, Mitt
contbr_st                             
AK              0.765778      0.234222
AL              0.507390      0.492610
AR              0.772902      0.227098
AZ              0.443745      0.556255
CA              0.679498      0.320502
CO              0.585970      0.414030
CT              0.371476      0.628524
DC              0.810113      0.189887
DE              0.802776      0.197224
FL              0.467417      0.532583

Process finished with exit code 0

```

