## SSH 설정

```
[bit44@hadoopnode01 ~]$ ssh-keygen -t rsa

```

> key 를 공유하면 password 없이 접근 가능

> password 를 따로 생성할건지 물어보지만 우리는 필요없음
>
> 전부 엔터

```
[bit44@hadoopnode01 ~]$ ls -al .ssh
합계 12
drwx------.  2 bit44 bit44   38  8월 20 01:19 .
drwx------. 17 bit44 bit44 4096  8월 20 01:19 ..
-rw-------.  1 bit44 bit44 1675  8월 20 01:19 id_rsa
-rw-r--r--.  1 bit44 bit44  400  8월 20 01:19 id_rsa.pub

```

> rsa : 개인키
>
> pub : 공개키

```
[bit44@hadoopnode01 ~]$ ssh-copy-id -i /home/bit44/.ssh/id_rsa.pub bit44@hadoopnode02

```

> 내가 만든 키를 하둡2 에 보내기
> 우리는 한 컴퓨터에서 진행하지만, 다른 컴퓨터에 이걸 보낸다고 생각하면 됨

```
Are you sure you want to continue connecting (yes/no)? yes
.
.
bit44@hadoopnode02's password:

```

> 비밀번호 입력 bit44

> 이후 비밀번호 없이 연결 가능

> 커맨드에는 hadoopnode01 이 나오는데, 같은 컴퓨터에서 접속했기 때문에 01로 나옴
>
> 실제로는 02로 접속했다고 봐야한다. (한 컴퓨터이기 때문에 03 04 역시 이미 적용이 되어있음)
> 만약 여러대 컴퓨터가 있다면 각 컴퓨터마다 다시 같은 방법으로 해줘야 한다.
>
> 서버를 전부 다 연결시켜 주기 위해서는
> 방금 namenode 를 통해 datanode 에 준것처럼
> datanode 기준으로 keygen 을 해서 연결해줘야 한다.
>
> namenode 에서만 보낸다면 안해도 되지만, 상호적으로 구동하기 위해선 각 기준으로 연결해줘야 한다.

```
[bit44@hadoopnode01 ~]$ ls -l
합계 207080
-rw-rw-r--. 1 bit44 bit44 212046774  1월 26  2016 hadoop-2.7.2.tar.gz
drwxrwxr-x. 2 bit44 bit44        39  8월 20 00:25 test01
drwxr-xr-x. 2 bit44 bit44         6  8월 18 21:55 공개
drwxr-xr-x. 2 bit44 bit44         6  8월 18 21:55 다운로드
drwxr-xr-x. 2 bit44 bit44         6  8월 18 21:55 문서
drwxr-xr-x. 2 bit44 bit44         6  8월 18 21:55 바탕화면
drwxr-xr-x. 2 bit44 bit44         6  8월 18 21:55 비디오
drwxr-xr-x. 2 bit44 bit44         6  8월 18 21:55 사진
drwxr-xr-x. 2 bit44 bit44         6  8월 18 21:55 서식
drwxr-xr-x. 2 bit44 bit44         6  8월 18 21:55 음악
[bit44@hadoopnode01 ~]$
[bit44@hadoopnode01 ~]$
[bit44@hadoopnode01 ~]$
[bit44@hadoopnode01 ~]$
[bit44@hadoopnode01 ~]$ tar zxvf hadoop-2.7.2.tar.gz

```

```
[bit44@hadoopnode01 ~]$ ln -s hadoop-2.7.2 hadoop

```

> hadoop 으로 심볼릭 파일을 만들어서 이름을 간단하게 만들어주기

```
[bit44@hadoopnode01 ~]$ cd hadoop
[bit44@hadoopnode01 ~/hadoop]$ vi etc/hadoop/hadoop-env.sh

```

> 환경설정 해주기

```
login as: bit44
bit44@127.0.0.1's password:
Last login: Thu Aug 20 01:06:05 2020 from gateway
[bit44@hadoopnode01 ~]$
[bit44@hadoopnode01 ~]$
[bit44@hadoopnode01 ~]$
[bit44@hadoopnode01 ~]$
[bit44@hadoopnode01 ~]$ cd hadoop
[bit44@hadoopnode01 ~/hadoop]$
[bit44@hadoopnode01 ~/hadoop]$
[bit44@hadoopnode01 ~/hadoop]$
[bit44@hadoopnode01 ~/hadoop]$
[bit44@hadoopnode01 ~/hadoop]$ mkdir pids
[bit44@hadoopnode01 ~/hadoop]$
[bit44@hadoopnode01 ~/hadoop]$
[bit44@hadoopnode01 ~/hadoop]$
[bit44@hadoopnode01 ~/hadoop]$ cd pids
[bit44@hadoopnode01 ~/hadoop/pids]$
[bit44@hadoopnode01 ~/hadoop/pids]$
[bit44@hadoopnode01 ~/hadoop/pids]$
[bit44@hadoopnode01 ~/hadoop/pids]$ pwd
/home/bit44/hadoop/pids

```

> 2번 째 세션

> pwd 커맨드의 경로 복사

```
export HADOOP_PID_DIR=/home/bit44/hadoop/pids

```

> 1번 째 세션의  해당 부분을 수정하여 붙여넣기

```
[bit44@hadoopnode01 ~/hadoop]$ vi masters

```

> 텍스트 파일 하나 생성 후 그냥 저장하고 나가기
>
> (세컨더리 네임노드의 호스트명 기술해주는 곳)

> namenode 와 secondary 는 한대씩 datanode는 여러대 가능
>
> (우리는 한대로 하니까 그 안에 hadoopnode01 라고 적어놓는다)

```
hadoopnode01

```

```
[bit44@hadoopnode01 ~/hadoop]$ mv masters etc/hadoop

```

> 하둡안에 마스터즈 만든 파일 넣어두기

```
[bit44@hadoopnode01 ~/hadoop]$ vi etc/hadoop/slaves
```

> 데이터노드의 호스트명을 전부 넣어주기

```
localhost
hadoopnode01

```

> 우리는 한대만 쓰니까 hadoopnode01 만 적어주면 되지만
> 만약 100대를 사용한다면 100대 이름 전부를 넣어줘야함

> se paste 적용하면, 자동 인덴테이션을 막아주기 때문에 무언가 붙여서 다시 정리할 필요가 없어짐
> se nopaste 로 원래상태 가능

```
[bit44@hadoopnode01 ~/hadoop]$ cd
[bit44@hadoopnode01 ~]$
[bit44@hadoopnode01 ~]$
[bit44@hadoopnode01 ~]$
[bit44@hadoopnode01 ~]$ mkdir hdfs-data
[bit44@hadoopnode01 ~]$ mkdir hdfs-data/hadoop
[bit44@hadoopnode01 ~]$ mkdir hdfs-data/hadoop/tmp

```

> 임시파일이 쌓이게 되는 하둡 파일 시스템의 접근 경로 만들기

```
[bit44@hadoopnode01 ~]$ cd hadoop
[bit44@hadoopnode01 ~/hadoop]$
[bit44@hadoopnode01 ~/hadoop]$
[bit44@hadoopnode01 ~/hadoop]$
[bit44@hadoopnode01 ~/hadoop]$
[bit44@hadoopnode01 ~/hadoop]$ vi etc/hadoop/core-site.xml

```

```
<configuration>
<property>
    <name>fs.defaultFS</name>
    <value>hdfs://hadoopnode01:9000</value>
</property>
<property>
    <name>hadoop.tmp.dir</name>
    <value>/home/bit44/dhfs-data/hadoop/tmp</value>
</property>
</configuration>

```

> 사이에 코드 넣어주기

> 작업하면서 임시로 만들어졌다가 만들고나서 삭제하는 파일들을 넣어두는 곳을 따로 지정함
> 물리적으로 디렉토리들을 나눠서 만들어주면, 각 node 들 에서 만들어지는 임시파일들이
> 나눠진 디렉토리로 들어가게 된다

> 리눅스 root 파일 밑에 들어가는 임시파일은 모든 것들이 몰리기 때문에
> 혹시라도 나중에 문제가 생겨 각 임시파일을 확인하고자 할때 분류되어 있는 파일들을 잘 확인하기 위해

> tmp 밑으로 계속 각 파일을 만들어두면 각 임시파일들이 가게 될 경로를 저장할 수 있다

```
[bit44@hadoopnode01 ~/hadoop]$ vi etc/hadoop/hdfs-site.xml
```

```
<configuration>
    <property>
        <name>dfs.replication</name>
        <value>1<value>
    </property>
    <property>
        <name>dfs.namenode.checkpoint.dir</name>
        <value>/home/bit44/hdfs-data/hadoop/data/name-secondary</value>
    </property>
    <property>
        <name>dfs.http.address</name>
        <value>hadoopnode01:50070</value>
    </property>
    <property>
        <name>dfs.secondary.http.address</name>
        <value>hadoopnode01:50090</value>
    </property>
    <property>
        <name>dfs.namenode.name.dir</name>
        <value>/home/bit44/hdfs-data/hadoop/data/namenode</value>
    </property>
    <property>
        <name>dfs.datanode.data.dir</name>
        <value>/home/bit44/hdfs-data/hadoop/data/datanode</value>
    </property>
</configuration>

```

>  <name>dfs.replication</name>		<<- 전체 코드가 namenode 에서 사용

> <value>1<value>			<<- datanode 개수를 넣는다. 우리는 컴퓨터 1대라서 1만 적음

> <name>dfs.namenode.checkpoint.dir</name>			<<- secondary 에서 사용

> <value>/home/jun/hdfs-data/hadoop/data/name-secondary</value>	<-새롭게 디렉토리 만들어줘야함

> <name>dfs.http.address</name>  	 <- namenode 주소

> <value>hadoopnode01:50070</value>  				<- 하둡에서 제공하는 것을 50070 포트로 받을거다. (50070은 관례상 지정한 포트번호)

> <name>dfs.secondary.http.address</name>  	<- secondary 주소

> <value>/home/jun/hdfs-data/hadoop/data/datanode</value>		<- 실제  파일들이 들어가는 곳

```
[bit44@hadoopnode01 ~]$ cd
[bit44@hadoopnode01 ~]$
[bit44@hadoopnode01 ~]$
[bit44@hadoopnode01 ~]$
[bit44@hadoopnode01 ~]$
[bit44@hadoopnode01 ~]$ vi ~/.bashrc

```

> 어느 위치에 있던 ~ 은 home 을 뜻함

```
# .bashrc

# Source global definitions
if [ -f /etc/bashrc ]; then
    . /etc/bashrc
fi

# Uncomment the following line if you don't like systemctl's auto-paging feature:
# export SYSTEMD_PAGER=

# User specific aliases and functions
PS1="[\u@\h \w]\\$ "
alias rm="rm -i"

set -o vi

export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.262.b10-0.el7_8.x86_64
export PATH=$PATH:$JAVA_HOME/bin
export CLASS_PATH=.:$JAVA_HOME/lib/tools.jar
export HADDOP_HOME=/home/bit44/hadoop-2.7.2

```

```
[bit44@hadoopnode01 ~]$ . .bashrc
```

```
[bit44@hadoopnode01 ~]$ cd hadoop
[bit44@hadoopnode01 ~/hadoop]$
[bit44@hadoopnode01 ~/hadoop]$
[bit44@hadoopnode01 ~/hadoop]$
[bit44@hadoopnode01 ~/hadoop]$
[bit44@hadoopnode01 ~/hadoop]$ cp etc/hadoop/mapred-site.xml.template etc/hadoop/mapred-site.xml

```

> hadoop 안의 etc 안의 hadoop 에 있는 파일들 중 복사해서 하나 생성

```
[bit44@hadoopnode01 ~/hadoop]$ vi etc/hadoop/mapred-site.xml

```

```
<configuration>
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
    <property>
        <name>yarn.app.mapreduce.am.env</name>
        <value>HADOOP_MAPRED_HOME=$HADOOP_HOME</value>
    </property>
    <property>
        <name>mapreduce.map.env</name>
        <value>HADOOP_MAPRED_HOME=$HADOOP_HOME</value>
    </property>
    <property>
        <name>mapreduce.reduce.env</name>
        <value>HADOOP_MAPRED_HOME=$HADOOP_HOME</value>
    </property>
</configuration>

```

> 빈 줄 없이 작성

> <value>yarn</value>				<- yarn 은 리소스 관리자 (필요할때 부하량에 따라 나눠쓸 수 있게 해주는 것)

```
[bit44@hadoopnode01 ~/hadoop]$ cd etc/hadoop
[bit44@hadoopnode01 ~/hadoop/etc/hadoop]$
[bit44@hadoopnode01 ~/hadoop/etc/hadoop]$
[bit44@hadoopnode01 ~/hadoop/etc/hadoop]$
[bit44@hadoopnode01 ~/hadoop/etc/hadoop]$
[bit44@hadoopnode01 ~/hadoop/etc/hadoop]$ vi yarn-site.xml

```

```
<configuration>
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
    <property>
        <name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>
        <value>org.apache.hadoop.mapred.ShuffleHandler</value>
    </property>
    <property>
        <name>yarn.nodemanager.local-dirs</name>
        <value>/home/bit44/hdfs-data/hadoop/data/yarn/local</value>
    </property>
    <property>
        <name>yarn.resourcemanager.fs.state-store.uri</name>
        <value>/home/bit44/hdfs-data/hadoop/data/yarn/rmstore</value>
    </property>
    <property>
        <name>yarn.nodemanager.hostname</name>
        <value>hadoopnode01</value>
    </property>
    <property>
        <name>yarn.web-proxy.address</name>
        <value>0.0.0.0:8090</value>
    </property>
    <property>
        <name>yarn.nodemanager.log-dir</name>
        <value>/home/bit44/hdfs-data/hadoop/data/yarn/logs</value>
    </property>
</configuration>

```

> <value>mapreduce_shuffle</value>			<- 셔플을 하라는 명령

> <value>org.apache.hadoop.mapred.ShuffleHandler</value>			<- 어디서 셔플을 할거냐

> scp -r /home/jun/hdfs-data/hadoop/etc/hadoop hadoopnode02:/home/jun/hdfs-data/hadoop/etc/hadoop
>
> 이 명령으로 처음에 하둡 설치를 잘 해놓으면, 다른 node에 이 코드로 같은 실행을 하게 만들어줄 수 있다.
> 우리는 한대로만 사용하기 때문에 할 필요 없지만, 머신 대 머신으로 복사해서 수행할 수 있게 만들어줌

```
[bit44@hadoopnode01 ~]$ cd hadoop
[bit44@hadoopnode01 ~/hadoop]$
[bit44@hadoopnode01 ~/hadoop]$
[bit44@hadoopnode01 ~/hadoop]$
[bit44@hadoopnode01 ~/hadoop]$ bin/hdfs namenode -format

```

> 처음 시작할때 포맷하기 때문에 한번 성공하면 할 필요 없음
> namenode 만 포맷하면 됨

> Storage directory /home/jun/hdfs-data/hadoop/data/namenode has been successfully formatted.
> 이 문장 나오면 된거
>
> 하지만 자료를 보고 따라한 것은 해당 문장이 뜨지 않음